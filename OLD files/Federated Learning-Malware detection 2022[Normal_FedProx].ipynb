{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55b69fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "173907af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "#from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import  keras\n",
    "# from tensorflow.keras import backend as K\n",
    "\n",
    "from federated_utils_fedavg import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4bf76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declear path to your data\n",
    "drebin_data_path = r'H:\\GIT project\\DW-FedAvg\\data\\drebin.csv'\n",
    "malgenome_data_path = r'H:\\GIT project\\DW-FedAvg\\data\\malgenome.csv'\n",
    "kronodroid_data_path = r'H:\\GIT project\\DW-FedAvg\\data\\kronodroid.csv'\n",
    "TUANDROMD_data_path=r'H:\\GIT project\\DW-FedAvg\\data\\TUANDROMD.csv'\n",
    "\n",
    "\n",
    "\n",
    "Drebin_data = pd.read_csv(drebin_data_path, header = None)\n",
    "\n",
    "Malgenome_data = pd.read_csv(malgenome_data_path)\n",
    "\n",
    "Tuandromd_data=pd.read_csv(TUANDROMD_data_path)\n",
    "\n",
    "kronodroid_data=pd.read_csv(kronodroid_data_path)\n",
    "Kronodroid_data = kronodroid_data.iloc[:,range(1,kronodroid_data.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da6c9299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================\n",
      "Working with: Drebin\n",
      "===================================================================================================\n",
      "---------------------------------------------\n",
      "No. of Clients: 5\n",
      "No. of Rounds: 10\n",
      "---------------------------------------------\n",
      "|=======================|\n",
      "|Traditional FedProx 2017|\n",
      "|=======================|\n",
      "94/94 [==============================] - 1s 10ms/step\n",
      "comm_round: 0 | global_acc: 97.839% | global_loss: 0.5653417706489563 | global_f1: 0.9704142011834319 | global_precision: 0.9797794117647058 | global_recall: 0.9612263300270514 | global_auc: 0.9951364939356341| flobal_FPR: 0.0387736699729486 \n",
      "94/94 [==============================] - 1s 8ms/step\n",
      "comm_round: 1 | global_acc: 98.138% | global_loss: 0.5644866228103638 | global_f1: 0.9746376811594203 | global_precision: 0.9790718835304822 | global_recall: 0.9702434625788999 | global_auc: 0.9954828866790028| flobal_FPR: 0.029756537421100092 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 152\u001b[0m\n\u001b[0;32m    149\u001b[0m local_model\u001b[39m.\u001b[39mset_weights(global_weights)\n\u001b[0;32m    151\u001b[0m \u001b[39m#fit local model with client's data\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m local_model\u001b[39m.\u001b[39;49mfit(clients_batched[client], epochs\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m    154\u001b[0m \u001b[39m#scale the model weights and add to list\u001b[39;00m\n\u001b[0;32m    155\u001b[0m scaling_factor \u001b[39m=\u001b[39m weight_scalling_factor(clients_batched, client)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:1377\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_function\u001b[39m(iterator):\n\u001b[0;32m   1376\u001b[0m     \u001b[39m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1377\u001b[0m     \u001b[39mreturn\u001b[39;00m step_function(\u001b[39mself\u001b[39;49m, iterator)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:1360\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1356\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1357\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1358\u001b[0m     )\n\u001b[0;32m   1359\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1360\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m   1361\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1362\u001b[0m     outputs,\n\u001b[0;32m   1363\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy,\n\u001b[0;32m   1364\u001b[0m     reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_reduction_method,\n\u001b[0;32m   1365\u001b[0m )\n\u001b[0;32m   1366\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1679\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1674\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1675\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1676\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1677\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1678\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1679\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3269\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3267\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   3268\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 3269\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4067\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   4065\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   4066\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 4067\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:596\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    595\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mUNSPECIFIED):\n\u001b[1;32m--> 596\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:1349\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1349\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m   1350\u001b[0m     \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1351\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:1127\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1125\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m   1126\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(x, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m-> 1127\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(x, y, y_pred, sample_weight)\n\u001b[0;32m   1128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m   1129\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:1185\u001b[0m, in \u001b[0;36mModel.compute_loss\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39m\"\"\"Compute the total loss, validate it, and return it.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[39mSubclasses can optionally override this method to provide custom loss\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1182\u001b[0m \u001b[39m  is the case when called by `Model.test_step`).\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m \u001b[39mdel\u001b[39;00m x  \u001b[39m# The default implementation does not use `x`.\u001b[39;00m\n\u001b[1;32m-> 1185\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompiled_loss(\n\u001b[0;32m   1186\u001b[0m     y, y_pred, sample_weight, regularization_losses\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlosses\n\u001b[0;32m   1187\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\compile_utils.py:277\u001b[0m, in \u001b[0;36mLossesContainer.__call__\u001b[1;34m(self, y_true, y_pred, sample_weight, regularization_losses)\u001b[0m\n\u001b[0;32m    275\u001b[0m y_t, y_p, sw \u001b[39m=\u001b[39m match_dtype_and_rank(y_t, y_p, sw)\n\u001b[0;32m    276\u001b[0m sw \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mapply_mask(y_p, sw, losses_utils\u001b[39m.\u001b[39mget_mask(y_p))\n\u001b[1;32m--> 277\u001b[0m loss_value \u001b[39m=\u001b[39m loss_obj(y_t, y_p, sample_weight\u001b[39m=\u001b[39;49msw)\n\u001b[0;32m    279\u001b[0m total_loss_mean_value \u001b[39m=\u001b[39m loss_value\n\u001b[0;32m    280\u001b[0m \u001b[39m# Correct for the `Mean` loss metrics counting each replica as a\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[39m# batch.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:143\u001b[0m, in \u001b[0;36mLoss.__call__\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     call_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m    140\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall, tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    141\u001b[0m     )\n\u001b[1;32m--> 143\u001b[0m losses \u001b[39m=\u001b[39m call_fn(y_true, y_pred)\n\u001b[0;32m    145\u001b[0m in_mask \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mget_mask(y_pred)\n\u001b[0;32m    146\u001b[0m out_mask \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mget_mask(losses)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:270\u001b[0m, in \u001b[0;36mLossFunctionWrapper.call\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m    263\u001b[0m     y_pred, y_true \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39msqueeze_or_expand_dimensions(\n\u001b[0;32m    264\u001b[0m         y_pred, y_true\n\u001b[0;32m    265\u001b[0m     )\n\u001b[0;32m    267\u001b[0m ag_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m    268\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn, tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    269\u001b[0m )\n\u001b[1;32m--> 270\u001b[0m \u001b[39mreturn\u001b[39;00m ag_fn(y_true, y_pred, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fn_kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filexc1nqr1j.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__custom_loss\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m     10\u001b[0m local_loss \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mbinary_crossentropy, (ag__\u001b[39m.\u001b[39mld(y_true), ag__\u001b[39m.\u001b[39mld(y_pred)), \u001b[39mdict\u001b[39m(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope)\n\u001b[1;32m---> 11\u001b[0m proximal_term \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(proximal_loss), (ag__\u001b[39m.\u001b[39;49mld(global_weights), ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(local_model)\u001b[39m.\u001b[39;49mget_weights, (), \u001b[39mNone\u001b[39;49;00m, fscope), ag__\u001b[39m.\u001b[39;49mld(lambda_)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     12\u001b[0m total_loss \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(local_loss) \u001b[39m+\u001b[39m ag__\u001b[39m.\u001b[39mld(proximal_term)\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args)\n\u001b[0;32m    442\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_o7zjzki.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__proximal_loss\u001b[1;34m(global_weights, local_weights, lambda_)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m squared_diff \u001b[39m=\u001b[39m [ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mreduce_sum, (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49msquare, (ag__\u001b[39m.\u001b[39;49mld(w) \u001b[39m-\u001b[39;49m ag__\u001b[39m.\u001b[39;49mld(v),), \u001b[39mNone\u001b[39;49;00m, fscope),), \u001b[39mNone\u001b[39;49;00m, fscope) \u001b[39mfor\u001b[39;49;00m w, v \u001b[39min\u001b[39;49;00m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mzip\u001b[39;49m), (ag__\u001b[39m.\u001b[39;49mld(local_weights), ag__\u001b[39m.\u001b[39;49mld(global_weights)), \u001b[39mNone\u001b[39;49;00m, fscope)]\n\u001b[0;32m     11\u001b[0m proximal_term \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m ag__\u001b[39m.\u001b[39mld(lambda_) \u001b[39m*\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mreduce_sum, (ag__\u001b[39m.\u001b[39mld(squared_diff),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_o7zjzki.py:10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m squared_diff \u001b[39m=\u001b[39m [ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mreduce_sum, (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49msquare, (ag__\u001b[39m.\u001b[39;49mld(w) \u001b[39m-\u001b[39;49m ag__\u001b[39m.\u001b[39;49mld(v),), \u001b[39mNone\u001b[39;49;00m, fscope),), \u001b[39mNone\u001b[39;49;00m, fscope) \u001b[39mfor\u001b[39;00m w, v \u001b[39min\u001b[39;00m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mzip\u001b[39m), (ag__\u001b[39m.\u001b[39mld(local_weights), ag__\u001b[39m.\u001b[39mld(global_weights)), \u001b[39mNone\u001b[39;00m, fscope)]\n\u001b[0;32m     11\u001b[0m proximal_term \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m ag__\u001b[39m.\u001b[39mld(lambda_) \u001b[39m*\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mreduce_sum, (ag__\u001b[39m.\u001b[39mld(squared_diff),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\ops\\math_ops.py:2429\u001b[0m, in \u001b[0;36mreduce_sum\u001b[1;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[0;32m   2366\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmath.reduce_sum\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreduce_sum\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m   2367\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   2368\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce_sum\u001b[39m(input_tensor, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2369\u001b[0m   \u001b[39m\"\"\"Computes the sum of elements across dimensions of a tensor.\u001b[39;00m\n\u001b[0;32m   2370\u001b[0m \n\u001b[0;32m   2371\u001b[0m \u001b[39m  This is the reduction operation for the elementwise `tf.math.add` op.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2426\u001b[0m \u001b[39m  @end_compatibility\u001b[39;00m\n\u001b[0;32m   2427\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2429\u001b[0m   \u001b[39mreturn\u001b[39;00m reduce_sum_with_dims(input_tensor, axis, keepdims, name,\n\u001b[0;32m   2430\u001b[0m                               _ReductionDims(input_tensor, axis))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\ops\\math_ops.py:2441\u001b[0m, in \u001b[0;36mreduce_sum_with_dims\u001b[1;34m(input_tensor, axis, keepdims, name, dims)\u001b[0m\n\u001b[0;32m   2433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce_sum_with_dims\u001b[39m(input_tensor,\n\u001b[0;32m   2434\u001b[0m                          axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2435\u001b[0m                          keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   2436\u001b[0m                          name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2437\u001b[0m                          dims\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2438\u001b[0m   keepdims \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m keepdims \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mbool\u001b[39m(keepdims)\n\u001b[0;32m   2439\u001b[0m   \u001b[39mreturn\u001b[39;00m _may_reduce_to_scalar(\n\u001b[0;32m   2440\u001b[0m       keepdims, axis,\n\u001b[1;32m-> 2441\u001b[0m       gen_math_ops\u001b[39m.\u001b[39;49m_sum(input_tensor, dims, keepdims, name\u001b[39m=\u001b[39;49mname))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:13607\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[0;32m  13605\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m  13606\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m> 13607\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m  13608\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mSum\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, \u001b[39minput\u001b[39;49m, axis, \u001b[39m\"\u001b[39;49m\u001b[39mkeep_dims\u001b[39;49m\u001b[39m\"\u001b[39;49m, keep_dims)\n\u001b[0;32m  13609\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m  13610\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lambda_ = 0.1  # Adjust the value based on your requirements  for Fedprox\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "def proximal_loss(global_weights, local_weights, lambda_):\n",
    "    squared_diff = [tf.reduce_sum(tf.square(w - v)) for w, v in zip(local_weights, global_weights)]\n",
    "    proximal_term = 0.5* lambda_ * tf.reduce_sum(squared_diff)\n",
    "    return proximal_term\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # Calculate the local loss (binary_crossentropy)\n",
    "    local_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred, from_logits=True)\n",
    "\n",
    "    # Calculate the proximal term\n",
    "    proximal_term = proximal_loss(global_weights, local_model.get_weights(), lambda_)\n",
    "\n",
    "    # Combine local loss and proximal term\n",
    "    total_loss = local_loss + proximal_term\n",
    "\n",
    "    return total_loss\n",
    "all_avg =[]\n",
    "\n",
    "all_std =[]\n",
    "\n",
    "n_clients = [5,10,15]\n",
    "n_round = [10,20]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = ['Drebin', 'Malgenome', 'Kronodroid', 'Tuandromd' ]\n",
    "\n",
    "\n",
    "# for d in range(0,1):\n",
    "for d in range(0,2):\n",
    "    if d == 0:\n",
    "        use_data = Drebin_data\n",
    "    elif d==1:\n",
    "        use_data = Malgenome_data\n",
    "    elif d==2:\n",
    "        use_data = Kronodroid_data\n",
    "    elif d==3:\n",
    "        use_data = Tuandromd_data\n",
    "        \n",
    "        \n",
    "    print('===================================================================================================')\n",
    "    print('Working with:',dataset[d])\n",
    "    print('===================================================================================================')\n",
    "\n",
    "    for r in n_round: #number of rounds loop\n",
    "        comms_round = r\n",
    "        for cl in n_clients: #number of clients loop\n",
    "            number_of_clients = cl\n",
    "\n",
    "            # from sklearn.utils import shuffle\n",
    "            # use_data = shuffle(use_data)\n",
    "            # use_data\n",
    "            print('---------------------------------------------')\n",
    "            print('No. of Clients:', number_of_clients)\n",
    "            print('No. of Rounds:', comms_round)\n",
    "            print('---------------------------------------------')\n",
    "\n",
    "\n",
    "            features = np.array(use_data.iloc[:,range(0,use_data.shape[1]-1)]) #feature set\n",
    "\n",
    "            labels = use_data.iloc[:,-1] #labels --> B : Benign and S\n",
    "\n",
    "\n",
    "            #Do feature scaling \n",
    "\n",
    "\n",
    "            X = preprocessing.StandardScaler().fit(features).transform(features)\n",
    "\n",
    "\n",
    "            #binarize the labels\n",
    "            lb = LabelBinarizer()\n",
    "            y = lb.fit_transform(labels)\n",
    "\n",
    "\n",
    "            #split data into training and test set\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                                y, shuffle=True,\n",
    "                                                                test_size=0.2, \n",
    "                                                                random_state=100)\n",
    "\n",
    "\n",
    "\n",
    "            #create clients -- Horizontal FL\n",
    "            clients = create_clients(X_train, y_train, num_clients=number_of_clients, initial='client')\n",
    "\n",
    "            #process and batch the training data for each client\n",
    "            clients_batched = dict()\n",
    "            for (client_name, data) in clients.items():\n",
    "                clients_batched[client_name] = batch_data(data)\n",
    "\n",
    "\n",
    "                #process and batch the test set  \n",
    "            test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))\n",
    "\n",
    "            #==============================================\n",
    "            # Traditional FedProx 2017\n",
    "            #==============================================\n",
    "            #-----------------------------------------------\n",
    "\n",
    "\n",
    "            all_results=list()\n",
    "\n",
    "            #create optimizer\n",
    "            lr = 0.01 \n",
    "            loss='binary_crossentropy'\n",
    "            metrics = ['accuracy']\n",
    "            optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr, \n",
    "                            decay=lr / comms_round, \n",
    "                            momentum=0.9\n",
    "                           )\n",
    "\n",
    "            #initialize global model\n",
    "            smlp_global = SimpleMLP()\n",
    "            global_model = smlp_global.build(X.shape[1],1)\n",
    "            #-----------------------------------------------\n",
    "\n",
    "\n",
    "            print('|=======================|')\n",
    "            print('|Traditional FedProx 2017|')\n",
    "            print('|=======================|')\n",
    "\n",
    "            #commence global training loop\n",
    "            for comm_round in range(comms_round):\n",
    "\n",
    "                # get the global model's weights - will serve as the initial weights for all local models\n",
    "                global_weights = global_model.get_weights()\n",
    "\n",
    "                #initial list to collect local model weights after scalling\n",
    "                scaled_local_weight_list = list()\n",
    "\n",
    "                #randomize client data - using keys\n",
    "                client_names= list(clients_batched.keys())\n",
    "                random.shuffle(client_names)\n",
    "\n",
    "                #loop through each client and create new local model\n",
    "                for client in client_names:\n",
    "                    smlp_local = SimpleMLP()\n",
    "                    local_model = smlp_local.build(X.shape[1],1)\n",
    "                    local_model.compile(loss=custom_loss, \n",
    "                                  optimizer=optimizer, \n",
    "                                  metrics=metrics)\n",
    "\n",
    "                    #set local model weight to the weight of the global model\n",
    "                    local_model.set_weights(global_weights)\n",
    "\n",
    "                    #fit local model with client's data\n",
    "                    local_model.fit(clients_batched[client], epochs=32, verbose=0)\n",
    "\n",
    "                    #scale the model weights and add to list\n",
    "                    scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "                    scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "                    scaled_local_weight_list.append(scaled_weights)\n",
    "\n",
    "                    #clear session to free memory after each communication round\n",
    "                    keras.backend.clear_session()\n",
    "\n",
    "                #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "                average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "\n",
    "                #update global model \n",
    "                global_model.set_weights(average_weights)\n",
    "\n",
    "                #test global model and print out metrics after each communications round\n",
    "                for(X_test, Y_test) in test_batched:\n",
    "                    global_acc, global_loss, global_f1, global_precision, global_recall, global_auc, global_fpr = test_model(X_test, Y_test, global_model, comm_round)\n",
    "                    all_results.append([global_acc,global_loss.numpy(),global_f1, global_precision, global_recall, global_auc, global_fpr])\n",
    "\n",
    "\n",
    "            all_R = pd.DataFrame(all_results, columns=['global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "            flname = 'results/round-'+str(r)+'/'+str(cl)+'-clients/FedProx-'+dataset[d]+'-results.csv'\n",
    "            all_R.to_csv(flname, index=None)\n",
    "            \n",
    "            \n",
    "            all_avg.append(np.concatenate(([dataset[d],r,cl],np.mean(all_results,axis=0)))) #Storing avg values for each dataset\n",
    "            all_std.append(np.concatenate(([dataset[d],r,cl],np.std(all_results,axis=0)))) #Storing std values sfor each dataset\n",
    "          \n",
    "\n",
    "            \n",
    "ALL_AVG = pd.DataFrame(all_avg, columns = ['Dataset', 'num of round', 'num of cliends','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_AVG.to_csv(f'FedProx-results.csv')     \n",
    "\n",
    "ALL_STD = pd.DataFrame(all_std, columns = ['Dataset', 'num of round', 'num of cliends','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_STD.to_csv('FedProx-all-std-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343ccec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Drebin' '10' '5' '0.9822805851063829' '0.5641639709472657'\n",
      " '0.9758701733506149' '0.9798174987444629' '0.9719567177637511'\n",
      " '0.9949485064276151' '0.028043282236248874']\n"
     ]
    }
   ],
   "source": [
    "print((all_avg[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2893319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================\n",
      "Working with: Drebin\n",
      "===================================================================================================\n",
      "---------------------------------------------\n",
      "No. of Clients: 5\n",
      "No. of Rounds: 10\n",
      "---------------------------------------------\n",
      "|=======================|\n",
      "|Traditional FedAvg 2017|\n",
      "|=======================|\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 128\u001b[0m\n\u001b[0;32m    125\u001b[0m local_model\u001b[39m.\u001b[39mset_weights(global_weights)\n\u001b[0;32m    127\u001b[0m \u001b[39m#fit local model with client's data\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m local_model\u001b[39m.\u001b[39;49mfit(clients_batched[client], epochs\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m    130\u001b[0m \u001b[39m#scale the model weights and add to list\u001b[39;00m\n\u001b[0;32m    131\u001b[0m scaling_factor \u001b[39m=\u001b[39m weight_scalling_factor(clients_batched, client)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m   \u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "all_avg =[]\n",
    "\n",
    "all_std =[]\n",
    "\n",
    "n_clients = [5,10,15]\n",
    "n_round = [10,20]\n",
    "\n",
    "\n",
    "dataset = ['Drebin', 'Malgenome', 'Kronodroid', 'Tuandromd' ]\n",
    "\n",
    "\n",
    "for d in range(0,1):\n",
    "    if d == 0:\n",
    "        use_data = Drebin_data\n",
    "    elif d==1:\n",
    "        use_data = Malgenome_data\n",
    "    elif d==2:\n",
    "        use_data = Kronodroid_data\n",
    "    elif d==3:\n",
    "        use_data = Tuandromd_data\n",
    "        \n",
    "        \n",
    "    print('===================================================================================================')\n",
    "    print('Working with:',dataset[d])\n",
    "    print('===================================================================================================')\n",
    "\n",
    "    for r in n_round: #number of rounds loop\n",
    "        comms_round = r\n",
    "        for cl in n_clients: #number of clients loop\n",
    "            number_of_clients = cl\n",
    "\n",
    "            # from sklearn.utils import shuffle\n",
    "            # use_data = shuffle(use_data)\n",
    "            # use_data\n",
    "            print('---------------------------------------------')\n",
    "            print('No. of Clients:', number_of_clients)\n",
    "            print('No. of Rounds:', comms_round)\n",
    "            print('---------------------------------------------')\n",
    "\n",
    "\n",
    "            features = np.array(use_data.iloc[:,range(0,use_data.shape[1]-1)]) #feature set\n",
    "\n",
    "            labels = use_data.iloc[:,-1] #labels --> B : Benign and S\n",
    "\n",
    "\n",
    "            #Do feature scaling \n",
    "\n",
    "\n",
    "            X = preprocessing.StandardScaler().fit(features).transform(features)\n",
    "\n",
    "\n",
    "            #binarize the labels\n",
    "            lb = LabelBinarizer()\n",
    "            y = lb.fit_transform(labels)\n",
    "\n",
    "\n",
    "            #split data into training and test set\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                                y, shuffle=True,\n",
    "                                                                test_size=0.2, \n",
    "                                                                random_state=100)\n",
    "\n",
    "\n",
    "\n",
    "            #create clients -- Horizontal FL\n",
    "            clients = create_clients(X_train, y_train, num_clients=number_of_clients, initial='client')\n",
    "\n",
    "            #process and batch the training data for each client\n",
    "            clients_batched = dict()\n",
    "            for (client_name, data) in clients.items():\n",
    "                clients_batched[client_name] = batch_data(data)\n",
    "\n",
    "\n",
    "                #process and batch the test set  \n",
    "            test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))\n",
    "\n",
    "            #==============================================\n",
    "            # Traditional FedProx 2017\n",
    "            #==============================================\n",
    "            #-----------------------------------------------\n",
    "\n",
    "\n",
    "            all_results=list()\n",
    "\n",
    "            #create optimizer\n",
    "            lr = 0.01 \n",
    "            loss='binary_crossentropy'\n",
    "            metrics = ['accuracy']\n",
    "            optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr, \n",
    "                            decay=lr / comms_round, \n",
    "                            momentum=0.9\n",
    "                           )\n",
    "\n",
    "            #initialize global model\n",
    "            smlp_global = SimpleMLP()\n",
    "            global_model = smlp_global.build(X.shape[1],1)\n",
    "            #-----------------------------------------------\n",
    "\n",
    "\n",
    "            print('|=======================|')\n",
    "            print('|Traditional FedProx 2017|')\n",
    "            print('|=======================|')\n",
    "\n",
    "            #commence global training loop\n",
    "            for comm_round in range(comms_round):\n",
    "\n",
    "                # get the global model's weights - will serve as the initial weights for all local models\n",
    "                global_weights = global_model.get_weights()\n",
    "\n",
    "                #initial list to collect local model weights after scalling\n",
    "                scaled_local_weight_list = list()\n",
    "\n",
    "                #randomize client data - using keys\n",
    "                client_names= list(clients_batched.keys())\n",
    "                random.shuffle(client_names)\n",
    "\n",
    "                #loop through each client and create new local model\n",
    "                for client in client_names:\n",
    "                    smlp_local = SimpleMLP()\n",
    "                    local_model = smlp_local.build(X.shape[1],1)\n",
    "                    local_model.compile(loss=loss, \n",
    "                                  optimizer=optimizer, \n",
    "                                  metrics=metrics)\n",
    "\n",
    "                    #set local model weight to the weight of the global model\n",
    "                    local_model.set_weights(global_weights)\n",
    "\n",
    "                    #fit local model with client's data\n",
    "                    local_model.fit(clients_batched[client], epochs=32, verbose=0)\n",
    "\n",
    "                    #scale the model weights and add to list\n",
    "                    scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "                    scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "                    scaled_local_weight_list.append(scaled_weights)\n",
    "\n",
    "                    #clear session to free memory after each communication round\n",
    "                    keras.backend.clear_session()\n",
    "\n",
    "                #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "                average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "\n",
    "                #update global model \n",
    "                global_model.set_weights(average_weights)\n",
    "\n",
    "                #test global model and print out metrics after each communications round\n",
    "                for(X_test, Y_test) in test_batched:\n",
    "                    global_acc, global_loss, global_f1, global_precision, global_recall, global_auc, global_fpr = test_model(X_test, Y_test, global_model, comm_round)\n",
    "                    all_results.append([global_acc,global_loss.numpy(),global_f1, global_precision, global_recall, global_auc, global_fpr])\n",
    "\n",
    "\n",
    "\n",
    "            all_R = pd.DataFrame(all_results, columns=['global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "            flname = 'results/round-'+str(r)+'/'+str(cl)+'-clients/FedProx-'+dataset[d]+'-results.csv'\n",
    "            all_R.to_csv(flname, index=None)\n",
    "            \n",
    "            \n",
    "            all_avg.append(np.concatenate(([dataset[d],r,cl],np.mean(all_results,axis=0)))) #Storing avg values for each dataset\n",
    "            all_std.append(np.concatenate(([dataset[d],r,cl],np.std(all_results,axis=0)))) #Storing std values sfor each dataset\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "ALL_AVG = pd.DataFrame(all_avg, columns = ['Dataset', 'num of round', 'num of cliends','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_AVG.to_csv(f'FedProx-results.csv')     \n",
    "\n",
    "ALL_STD = pd.DataFrame(all_std, columns = ['Dataset', 'num of round', 'num of cliends','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_STD.to_csv('FedProx-all-std-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6104c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_AVG = pd.DataFrame(all_avg, columns = ['Dataset','Rounds','no-clients','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_AVG.to_csv('FedProx-all-avg-results.csv')\n",
    "\n",
    "ALL_STD = pd.DataFrame(all_std, columns = ['Dataset','Rounds','no-clients','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_STD.to_csv('FedProx-all-std-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0c3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0gUlEQVR4nO3dd3yV9fn/8deVkz1IIISAbGUIspEhKoLYirWCFC3gQr5W8Fttqa2zP7+O9qG1xbZYxTqpWm3AATjqQBDEgUzD3soIIIQRkpCdXL8/zp3kEAM5yTnJnXE9H4/zyD0/5zofIG/ucT63qCrGGGNMMIS4XYAxxpjGw0LFGGNM0FioGGOMCRoLFWOMMUFjoWKMMSZoLFSMMcYEjSuhIiKzReSwiGw8zXoRkX+IyE4RWS8iA3zWTRaRHc5rct1VbYwxpipuHam8DIw+w/orgK7OayrwTwARaQE8BAwBBgMPiUjzWq3UGGOM31wJFVVdBhw7wyZjgVfV62sgQUTaAJcDn6jqMVU9DnzCmcPJGGNMHQp1u4DTaAvs85lPc5adbvkPiMhUvEc5REZGDuzQoUPtVNrAlJSUEBJil9LA+sKX9UU564ty27dvP6KqSdXZp76GSsBU9XngeYDu3bvrtm3bXK6ofli6dCkjRoxwu4x6wfqinPVFOeuLciKyp7r71Nc43g+095lv5yw73XJjjDH1QH0NlXeBm5y7wIYCJ1T1IPAx8GMRae5coP+xs8wYY0w94MrpLxFJAUYALUUkDe8dXWEAqvos8AHwE2AnkANMcdYdE5E/Aqucpv6gqme64G+MMaYOuRIqqjqpivUK3H6adbOB2bVRlzEm+AoLC0lLSyMvL8/tUvwSHx/Pli1b3C6jTkVGRtKuXTvCwsICbqvRXqg3xtQPaWlpxMXF0alTJ0TE7XKqlJWVRVxcnNtl1BlV5ejRo6SlpdG5c+eA26uv11SMMY1EXl4eiYmJDSJQmiIRITExMWhHkhYqxphaZ4FSvwXzz8dCxRhjTNBYqBhjmoQFCxYgImzdurVW3+fuu+/mvPPO4+677z5l+csvv0xSUhL9+vWjX79+3HTTTX63+fDDD/PEE0+UzRcVFZGUlMR9990XtLqDxULFGNMkpKSkcNFFF5GSklKr7/P888+zfv16ZsyY8YN1EyZMIDU1ldTUVF599dUav8cnn3xCt27dePPNN/HeLFt/WKgYYxq97OxsvvjiC1566SXmzJlTtry4uJi77rqLXr160adPH5566ikAVq1axbBhw+jbty+DBw8mKyvrlPZUlbvvvptevXrRu3dv5s6dC8CYMWPIzs5m4MCBZcuqMmPGDAYNGkSfPn146KGHypY/+uijdOvWjYsuuoiKw0ylpKQwffp0OnTowPLlyykpKaFTp05kZGSUbdO1a1cOHTrErl27GDp0KL179+aBBx4gNja2Wn1XXXZLsTGmzjzy3iY2H8gMaps9z2rGQ1edd8Zt3nnnHUaPHk23bt1ITExkzZo1DBw4kOeff57du3eTmppKaGgox44do6CggAkTJjB37lwGDRpEZmYmUVFRp7Q3b948UlNTWbduHUeOHGHQoEEMHz6cd999l9jYWFJTUyutY+7cuXzxxRcATJ8+nbZt27Jjxw5WrlyJqjJmzBiWLVtGTEwMc+bMITU1laKiIgYMGMDAgQMB7910ixYt4rnnniMjI4OUlBSGDRvG2LFjmT9/PlOmTGHFihV07NiR5ORkbrnlFqZPn86kSZN49tlnA+/wKtiRijGm0UtJSWHixIkATJw4sewU2KJFi5g2bRqhod7/X7do0YIdO3bQpk0bBg0aBECzZs3K1pf64osvmDRpEh6Ph+TkZC655BJWrVpFVXxPf02ZMoWFCxeycOFC+vfvz4ABA9i6dSs7duzg888/Z9y4cURHR9OsWTPGjBlT1sb777/PyJEjiYqKYvz48SxYsIDi4uKyIASYM2cOEyZMAGD58uVce+21AFx33XWBdKNf7EjFGFNnqjqiqA3Hjh3j008/ZcOGDYgIxcXFiEil1zzqmqpy//33M23atFOWz5w587T7pKSk8MUXX9CpUycAjh49yqeffspll13Gzp07SU9PZ8GCBTzwwAO1WPnp2ZGKMaZRe+utt7jxxhvZs2cPu3fvZt++fXTu3JnPP/+cH/3oRzz33HMUFRUB3gDq2rUrBw8eLDvyyMrKKltf6uKLL2bu3LkUFxeTnp7OsmXLGDx4cLVru/zyy5k9ezbZ2dkA7N+/n8OHDzN8+HAWLFhAbm4uWVlZvPfeewBkZmby+eefs3fvXnbv3s3u3buZNWsWKSkpiAjjxo3jt7/9LT169CAxMRGAoUOH8vbbbwOccj2pttiRijGmUUtJSeHee+89Zdn48eNJSUnhqaeeYvv27fTp04ewsDBuvfVWJk+ezNy5c/nVr35Fbm4uUVFRLFq06JQL3OPGjWP58uX07dsXEeEvf/kLrVu3rnZtP/7xj9myZQsXXHABALGxsbz22msMGDCACRMm0LdvX1q1alV2Km7+/PlceumlRERElLUxduxY7rnnHvLz85kwYQKDBg3i5ZdfLls/c+ZMbrjhBh599FFGjx5NfHx8teusDqlvt6PVBntIVzl7AFE564tytdkXW7ZsoUePHrXSdm1obGN/5eTkEBUVhYgwZ84cUlJSeOedd36wXWV/TiKyRlXPr8772ZGKMcY0YmvWrOGOO+5AVUlISGD27Nod5N1CxRhjGrGLL76YdevW1dn72YV6Y0ytawqn2RuyYP75WKgYY2pVZGQkR48etWCpp0qfpxIZGRmU9uz0lzGmVrVr1460tDTS09PdLsUveXl5QfsF21CUPvkxGAIKFRG5CvivqpYEpRpjTKMTFhYWlCcK1pWlS5fSv39/t8tosAI9/TUB2CEifxGRc4NRkDHGmIYroFBR1RuA/sAu4GURWS4iU0Wk8dzkbYwxxm8BX6hX1UzgLWAO0AYYB6wVkV8F2rYxxpiGJdBrKmOAKUAX4FVgsKoeFpFoYDPwVOAlGmOC6fjJArYdymK789p5OJvDR3OZuelLt0urFzIz3e+LxJhwXrp5kKs11FSgd3+NB/6uqst8F6pqjojcEmDbxpgAZOUVsv1QNjsOZZWFyLbvszmSnV+2TbPIULomxxEdJjSLCnOx2vqjKNf9voiNbLg35gZa+cPAwdIZEYkCklV1t6ouDrBtY4wf8gqL2Xk4m23flx99bD+Uzf6M3LJtosI8dEuOZWT3JLq3jqNrchzdk+NIbhaBiDhjf1V/lN3GyPoiMIGGypvAMJ/5YmdZwzxuM6YeKygq4bsjJ8uCozRE9hzLofR7heGeEM5OiuH8Ts25LrkD3ZPj6N46jrYJUYSEiLsfwDQJgYZKqKoWlM6oaoGIhAfYpjFNWnGJsvdYToUjjyy+TT9JUYk3PUIEOreMoUebZozt15burePolhxHp8RoQj02UIZxT6Chki4iY1T1XQARGQscCbysxic7v4iSejBMRU6hkplX6HYZ9UJ96IvM3EJ2HMr2XvP43nvtY+fhbPKLyr9P3L5FFN2T4xjVI5nuyd7wODsphsgwj4uVG1O5QEPlNuB1EXkaEGAfcFPAVTUiq3cf468Lt7P826Nul1Ju8UK3K6g/6lFfJDeLoFtyHDcO7Ug358ija6tYYiIa7kVb0/QE9LdVVXcBQ0Uk1pnPDkpVjcC6fRn89ZPtLNueTsvYCH49qivN6sEdHbt27eKcc85xu4x6oT70RVS4h27JcXRrFUd8tN19ZRq+gH/LiciVwHlApIj3QqCq/iHQdhuqzQcy+dsn21m05RDNo8O4/4pzufGCjkSHux8oAEuL9zLi4rPdLqNesL4wJvgC/fLjs0A0MBJ4EbgGWBmEuhqcHYey+Pui7Xyw4XuaRYZy14+7cfOFnYm1UxfGmCYk0N94w1S1j4isV9VHROSvwIfBKKyh+O7ISZ5ctJ131h0gOszDry/twi0Xn028fZHMGNMEBRoqec7PHBE5CziKd/yvRm/fsRz+sXgH877ZT5hHmDr8bKYNP4cWMXZHtTGm6Qo0VN4TkQRgBrAWUOCFQIuqzw6eyOXpT3fyxup9iAiTL+jE/444h6S4CLdLM8YY19U4VEQkBFisqhnA2yLyPhCpqif82Hc08CTgAV5U1ccrrO8IzAaSgGPADaqa5qz7M3Cls+kfVXVuTT9DdRzOyuOZJbv4z8q9qCoTBrXn9pFdaBMfVRdvb4wxDUKNQ0VVS0RkFt7nqaCq+UD+mfcCEfEAs4AfAWnAKhF5V1U3+2z2BPCqqr4iIpcCfwJudO40GwD0AyKApSLyoTP8fq04drKA5z7bxSvLd1NYrIwf0JZfXdqV9i2ia+stjTGmwQr09NdiERkPzFP1++vig4GdqvotgIjMAcbiHSq/VE/gt870EmCBz/JlqloEFInIemA08EZAn6ISJ3IKeeHzb/nXl9+RU1jM1f3aMn1UVzq1jAn2WxljTKMRaKhMw/vLv0hE8vB+q15VtdkZ9mmL95v3pdKAIRW2WQf8DO8psnFAnIgkOssfcu4yK72VeTOVEJGpwFSApKQkli5d6tcHyi1SFu4u5KPdheQWwaDWHq7uEkXb2Ax2b1zFbr9aqb+ys7P97ovGzvqinPVFOeuLwAT6jfraemzwXcDTInIzsAzYDxSr6kIRGQR8BaQDy/GOjFxZbc8DzwN0795dR4wYccY3zCko4tXle3j2q11k5BTyo57J3HlZN3qedaZ8bHi8w3qPcLuMesH6opz1RTnri8AE+uXH4ZUtr/jQrgr2A+195ts5y3z3P4D3SAVnCJjxzg0BqOqjwKPOuv8A22tYPuB9FsXrK/byz6U7OZJdwCXdkvjtj7rRt31CIM0aY0yTFOjpr7t9piPxXi9ZA1x6hn1WAV1FpDPeMJkIXOe7gYi0BI6paglwP947wUov8ieo6lER6QP0AWo0ImBBUQlzV+/j6U93cCgzn2HnJPLsDd04v1OLmjRnjDGGwE9/XeU7LyLtgZlV7FMkIncAH+O9pXi2qm4SkT8Aq51h9EcAfxIRxXv663Zn9zDgc2eMsUy8txoXVafmwuIS5q1N4x+Ld7I/I5fzOzbn7xP6MeycltVpxhhjTCWCPTBVGtCjqo1U9QPggwrLHvSZfgt4q5L98vDeAVZtxSXKu+v28+SiHew+mkPfdvE89rPeDO/aktKBMI0xxgQm0GsqT+H9Fj1ACN7vj6wNsKagO1moXD5zGTsPZ9OjTTNeuOl8LuvRysLEGGOCLNAjldU+00VAiqp+GWCbQZeeq5wLPHP9AEaf19qe1W2MMbUk0FB5C8hT1WLwXkgXkWhVzQm8tOBpGSV8/JvheCxMjDGmVoUEuP9iwHfwqyhgUYBtBl1smFigGGNMHQg0VCJ9HyHsTNugWMYY00QFGionRWRA6YyIDARyA2zTGGNMAxXoNZXfAG+KyAG84361BiYEWpQxxpiGKdAvP64SkXOB7s6ibapaGHhZxhhjGqKATn+JyO1AjKpuVNWNQKyI/DI4pRljjGloAr2mcmvpQI8AqnocuDXANo0xxjRQgYaKR3y+lu4M+BgeYJvGGGMaqEAv1H8EzBWR55z5acCHAbZpjDGmgQo0VO7F+3TF25z59XjvADPGGNMEBXT6y3neyQpgN95nqVwKbAm8LGOMMQ1RjY5URKQbMMl5HQHmAqjqyOCVZowxpqGp6emvrcDnwE9VdSeAiNwZtKqMMcY0SDU9/fUz4CCwREReEJFReL9Rb4wxpgmrUaio6gJVnQicCyzBO1xLKxH5p4j8OIj1GWOMaUACvVB/UlX/4zyrvh3wDd47wowxxjRBgX75sYyqHlfV51V1VLDaNMYY07AELVSMMcYYCxVjjDFBY6FijDEmaCxUjDHGBI2FijHGmKCxUDHGGBM0FirGGGOCxkLFGGNM0FioGGOMCRoLFWOMMUFjoWKMMSZoLFSMMcYEjYWKMcaYoLFQMcYYEzSuhIqIjBaRbSKyU0Tuq2R9RxFZLCLrRWSpiLTzWfcXEdkkIltE5B8iYk+cNMaYeqLOQ0VEPMAs4AqgJzBJRHpW2OwJ4FVV7QP8AfiTs+8w4EKgD9ALGARcUkelG2OMqYIbRyqDgZ2q+q2qFgBzgLEVtukJfOpML/FZr0AkEA5EAGHAoVqv2BhjjF9CXXjPtsA+n/k0YEiFbdYBPwOeBMYBcSKSqKrLRWQJcBAQ4GlV3VLZm4jIVGCqM5svIhuD+BkaspbAEbeLqCesL8pZX5SzvijXvbo7uBEq/rgLeFpEbgaWAfuBYhHpAvQASq+xfCIiF6vq5xUbUNXngecBRGS1qp5fJ5XXc9YX5awvyllflLO+KCciq6u7jxuhsh9o7zPfzllWRlUP4D1SQURigfGqmiEitwJfq2q2s+5D4ALgB6FijDGm7rlxTWUV0FVEOotIODAReNd3AxFpKSKltd0PzHam9wKXiEioiIThvUhf6ekvY4wxda/OQ0VVi4A7gI/xBsIbqrpJRP4gImOczUYA20RkO5AMPOosfwvYBWzAe91lnaq+58fbPh/Ej9DQWV+Us74oZ31RzvqiXLX7QlS1NgoxxhjTBNk36o0xxgSNhYoxxpigadShUtVwME2FiLQXkSUistkZ4ma62zW5TUQ8IvKNiLzvdi1uEpEEEXlLRLY6Qx9d4HZNbhGRO51/HxtFJEVEIt2uqa6IyGwROez7fT4RaSEin4jIDudnc3/aarSh4udwME1FEfA7Ve0JDAVub8J9UWo6ducgeL9g/JGqngv0pYn2iYi0BX4NnK+qvQAP3jtTm4qXgdEVlt0HLFbVrsBiZ75KjTZU8G84mCZBVQ+q6lpnOgvvL4627lblHmeA0iuBF92uxU0iEg8MB14CUNUCVc1wtSh3hQJRIhIKRAMHXK6nzqjqMuBYhcVjgVec6VeAq/1pqzGHSmXDwTTZX6SlRKQT0B9Y4XIpbpoJ3AOUuFyH2zoD6cC/nFOBL4pIjNtFuUFV9+MdyHYv3mGgTqjqQnercl2yqh50pr/H+/WOKjXmUDEVOKMTvA38RlUz3a7HDSLyU+Cwqq5xu5Z6IBQYAPxTVfsDJ/HzFEdj41wvGIs3aM8CYkTkBnerqj/U+90Tv75/0phDpcrhYJoSZwSCt4HXVXWe2/W46EJgjIjsxntK9FIRec3dklyTBqSpaulR61t4Q6Ypugz4TlXTVbUQmAcMc7kmtx0SkTYAzs/D/uzUmEOlyuFgmgrnQWYvAVtU9W9u1+MmVb1fVdupaie8fyc+VdUm+T9SVf0e2CcipSPRjgI2u1iSm/YCQ0Uk2vn3MoometOCj3eByc70ZOAdf3aqr6MUB0xVi0SkdDgYDzBbVTe5XJZbLgRuBDaISKqz7Peq+oF7JZl64lfA685/vL4FprhcjytUdYWIvAWsxXu35Dc0oeFaRCQF7/BYLUUkDXgIeBx4Q0RuAfYAP/erLRumxRhjTLA05tNfxhhj6piFijHGmKCxUDHGGBM0FirGGGOCxkLFGGNM0FioGFNDIlIsIqnOqLbviUhCLb/fzSLydG2+hzGBslAxpuZyVbWfM6rtMeB2twsyxm0WKsYEx3KcAUtFpJ+IfC0i60VkfulzKERkqYic70y3dIaKKT0CmSciHznPrvhLaaMiMkVEtovISrxfYi1dfq1zhLRORJbV4ec05owsVIwJkPPsnlGUDwP0KnCvqvYBNuD9dnJV+gETgN7ABOfBam2AR/CGyUV4nwtU6kHgclXtC4wJxucwJhgsVIypuShn2JvSYcE/cZ5RkqCqnznbvIL3mSVVWayqJ1Q1D+/4Wx2BIcBSZ5DDAmCuz/ZfAi+LyK14hyEypl6wUDGm5nJVtR/eABCqvqZSRPm/uYqPqs33mS6minH5VPU24AG8I3GvEZFEP2s2plZZqBgTIFXNwfso2t/hfSbJcRG52Fl9I1B61LIbGOhMX+NH0yuAS0Qk0Xl0wbWlK0TkHFVdoaoP4n3QVvvTNWJMXWq0oxQbU5dU9RsRWQ9MwjtM+LMiEs2pI/8+gXfU16nAf/1o86CIPIz3JoAMINVn9QwR6Yr3CGkxsC44n8SYwNgoxcYYY4LGTn8ZY4wJGgsVY4wxQWOhYowxJmgsVIwxxgSNhYoxxpigsVAxxhgTNBYqxhhjgsZCxRhjTNBYqBhjjAkaCxVjjDFBY6FijDEmaCxUjDHGBI2FijHGmKBpEkPfJyQkaJcuXdwuo144efIkMTExbpdRL1hflLO+KGd9UW7NmjVHVDWpOvs0iVBJTk5m9erVbpdRLyxdupQRI0a4XUa9YH1RzvqinPVFORHZU9197PSXMcaYoGkSoXIszx5EZowxdaFJhEpmgZKycq/bZRhjTKPXJK6pRIUK/7dgI51bxjD07ES3yzGm0SksLCQtLY28vDy3SwlYfHw8W7ZscbuMOhUZGUm7du0ICwsLuK0mESpJUUL7xGj+97U1vHvHRbRvEe12ScY0KmlpacTFxdGpUydExO1yApKVlUVcXJzbZdQZVeXo0aOkpaXRuXPngNtrEqe/QgRemjyIEoVfvLKa7Pwit0syplHJy8sjMTGxwQdKUyQiJCYmBu0os0mECkDnljHMum4AO9Oz+c2cbygusYv3xgSTBUrDFcw/uyYTKgAXdW3Jgz/tyaIth3li4Ta3yzHGmEanSYUKwE0XdOS6IR3459JdLPhmv9vlGGOCxOPx0K9fv7LX448/Xuc1bN26lX79+tG/f3927dp1yrpOnTrRu3fvsvq++uorv9uNjY09ZX7mzJlERkZy4sSJoNQdTE3iQr0vEeGRMeex63A297y9no6J0fTv0NztsowxAYqKiiI1NfWM2xQXF+PxeE477+9+p7NgwQKuueYaHnjggUrXL1myhJYtW1bZTlVSUlIYNGgQ8+bNY8qUKQG3F0y1GioiMhp4EvAAL6rq4xXW3wzMAEoPGZ5W1RdFZCTwd59NzwUmquoCEXkdOB8oBFYC01S1sDp1hXlC+OcNAxk76wum/nsN795xIW3io2ryEY0xFTzy3iY2H8gMaps9z2rGQ1edV6N9O3XqxIQJE/jkk0+45557uO+++06ZV1Uee+wxVJUrr7yyLBBiY2OZNm0aixYtYtasWVx00UVlbaampnLbbbeRk5PDOeecw+zZs1m+fDkzZ87E4/GwePFilixZUmVtu3bt4vbbbyc9PZ3o6GheeOEFzj33XL777juuu+46srOzGTt27A/2yc7O5plnnuHRRx9lypQpPPvss+zatYsZM2YA8PLLL7N69Wqefvpp/vjHP/Laa6+RlJRE+/btGThwIHfddVeN+tIftXb6S0Q8wCzgCqAnMElEelay6VxV7ee8XgRQ1SWly4BLgRxgobP963hDpjcQBfyiJvW1iAnnpcmDyMkvYuqra8gtKK5JM8aYeiI3N/eU019z584tW5eYmMjatWuZOHHiKfPDhw/n3nvv5dNPPyU1NZVVq1bx/vvvA96BJYcMGcK6detOCRSAm266iT//+c+sX7+e3r1788gjj/CTn/yE2267jTvvvPO0gTJy5Ej69evHkCFDAJg6dSpPPfUUa9as4YknnuCXv/wlANOnT+d///d/2bBhA23atDmljTlz5jBx4kQuvvhitm3bxqFDhxg/fjzz588v22bu3LlMnDiRVatW8fbbb7Nu3To+/PDDOhkDsTaPVAYDO1X1WwARmQOMBTZXs51rgA9VNQdAVT8oXSEiK4F2NS2wW3Ic/5jUn1+8upq73lrH05P62x0sxgSopkcUgTrT6a8JEyZUOr9q1SpGjBhBUpJ3IN7rr7+eL7/8kkmTJuHxeBg/fvwP2jpx4gQZGRlccsklAEyePJlrr73Wrxp9T39lZ2fz1VdfnbJvfn4+AF9++SVvv/02ADfeeCP33ntv2TYpKSnMnz+fkJAQxo8fz5tvvskdd9zB2Wefzddff03Xrl3ZunUrF154IU8++SRjx44lMjKSyMhIrrrqKr/qDERthkpbYJ/PfBowpJLtxovIcGA7cKeq7quwfiLwt4o7iUgYcCMwvbI3F5GpwFSApKQkli5dWmmRHuDarmG8sf4g4TlHGNsl/EyfqcHLzs4+bV80NdYX5QLti/j4eLKysoJXUA1VVoOqoqpl63znc3NzKSwsLFuXl5dXti4yMpKcnJxK38O3vezsbEpKSsjKyiI/P5+wsLDT1pGdnU1ERAQAmZmZxMfH8/nnn1fafnZ2NqGhoWVtZWVlsWnTJnbs2MFll10GQEFBAR07dmTy5MlcffXVvPbaa3Tr1o0rr7yS7Oxs8vLyyM/PL2ujoKDglHlfeXl5wfn3UNrBwX7hPcJ40Wf+RrzXTHy3SQQinOlpwKcV1rcB0oGwStp/AZjpTy3dunXTMykpKdE753yjHe99Xz/ccOCM2zZ0S5YscbuEesP6olygfbF58+bgFBKAmJiYSpd37NhR09PTK50/cOCAdujQQdPT07WoqEhHjRqlKSkpZ2xPVbVPnz66bNkyVVV96KGH9De/+U3Z9IwZM/yqQ1X1ggsu0DfeeENVvb+HUlNTVVX1qquu0n//+9+qqvrMM8+U1XL//ffrY489dkobnTp10t27d+uxY8f07LPP1hEjRuiKFStUVXXlypXav39/zc3N1aysLO3atetp66vszxBYrdX83V+btxTvB9r7zLej/II8AKp6VFXzndkXgYEV2vg5MF8rXIgXkYeAJOC3wShURHjsZ73p3yGBO+euY9OB+nebnjHmzCpeU7nvvvuq3KdNmzY8/vjjjBw5kr59+zJw4ECuvPLKKvd75ZVXuPvuu+nTpw+pqak8+OCDNar59ddf56WXXqJv376cd955vPPOOwA8+eSTzJo1i969e7N/f/mvzTlz5jBu3LhT2hg3bhxz5syhefPm9OjRgz179jB48GAABg0axJgxY+jTpw9XXHEFvXv3Jj4+vka1+q26KeTvC++ptW+BzkA4sA44r8I2bXymxwFfV1j/NTCywrJfAF8BUf7WUtWRSqlDmbk69LFFesFji/RwZp5f+zQ09r/zctYX5RrDkUqwZGZmul1CUGVlZamq6smTJ3XgwIG6Zs2aSrer90cqqloE3AF8DGwB3lDVTSLyBxEZ42z2axHZJCLrgF8DN5fuLyKd8B7pfFah6WeBZGC5iKSKSM3+i1CJVnGRvHDT+RzLKeC219aQX2R3hBljGrapU6fSr18/BgwYwPjx4xkwYECtvl+tfk9FvXdqfVBh2YM+0/cD959m3914L/ZXXF6rNfdqG89fr+3H7f9Zy/+bv5EZ1/SxO8KMMQ3Wf/7znzp9vyY3TIs/ruzThumjuvLWmjRe+uI7t8sxpkHwni0xDVEw/+wsVE5j+qiuXNGrNY99sIUl2w67XY4x9VpkZCRHjx61YGmA1HmeSmRkZFDaa3Jjf/krJET468/7suefOfz6P98w//ZhdGnVdB7cY0x1tGvXjrS0NNLT090uJWB5eXlB+wXbUJQ++TEYLFTOIDo8lBcmn8/Yp7/klldWs+CXF9I8pnF/OdKYmggLCwvKUwPrg6VLl9K/f3+3y2iw7PRXFdomRPHcjQM5mJHH7f9ZS2FxidslGWNMvWWh4oeBHZvz2M9689Wuo/zx/eoOXWaMMU2Hnf7y0zUD27HjUBbPLfuWbslx3DC0o9slGWNMvWNHKtVwz+hzufTcVjz87ia+2nXE7XKMMabesVCpBk+I8OTEfnRuGcMvX1/LnqMn3S7JGGPqFQuVaoqLDOPFyecDcMsrq8nKq9ZDJ40xplGzUKmBjokxPHP9AHYfOcn0OakUl9gXvowxBixUamzYOS15eMx5fLr1MH/5aKvb5RhjTL1Q5d1f4h1NsZ3+8ImMTd4NQzuy3bkjrGtyHNcMDM43Uo0xpqGq8kjFGVP/g6q2a6r+76c9GXZOIr+ft4E1e467XY4xxrjK39Nfa0VkUK1W0kCFeUJ45voBtEmIZNq/13AgI9ftkowxxjX+hsoQvA/F2iUi60Vkg4isr83CGpKE6HBemnw++YXF3PrqanIKitwuyRhjXOFvqFwOnANcClwF/NT5aRxdWsXxj+v6s+VgJr97Yx0ldkeYMaYJ8itUVHUPkIA3SK4CEpxlxsfI7q34/U968OHG73ly8Q63yzHGmDrnV6iIyHTgdaCV83pNRH5Vm4U1VLdc1JlrBrbjycU7+O/6g26XY4wxdcrfASVvAYao6kkAEfkzsBx4qrYKa6hEhEfH9eK7Iyf53ZupdEyMplfbeLfLMsaYOuHvNRUBin3mi51lphIRoR6evWEgiTER3Prqag5n5bldkjHG1Al/Q+VfwAoReVhEHga+Bl6qtaoagaS4CJ6/aSAZOYVM+/ca8gqLq97JGGMauCpDRURC8IbIFOCY85qiqjNrt7SG77yz4vn7hL58szeDu95cx/GTBW6XZIwxtarKayqqWiIis1S1P7C2DmpqVEb3asPdl3dnxsfbWLj5ED/t3Ybrh3ZkQIcEvCPgGGNM4+HvhfrFIjIemOcM22Kq4faRXbisRzKvfb2H+d/sZ943++nRphk3DO3A1f3aEhNhD+A0xjQO/l5TmQa8CeSLSKaIZIlIZi3W1eh0bx3HH6/uxde/H8Wj43oB8P/mb2TIY4t58J2NbD+U5XKFxhgTOH9GKQ4BRqvql3VQT6MXGxHK9UM6ct3gDqzdm8HrX+9hzqp9vLp8D4M7teD6oR0Y3as1EaEet0s1xphq82eU4hLg6Zo0LiKjRWSbiOwUkfsqWX+ziKSLSKrz+oWzfKTPslQRyRORq511nUVkhdPmXBEJr0ltbhMRBnZszt8m9OPr+0dx/xXn8n1mHtPnpDLsT5/y54+2su9YjttlGmNMtfh7+muxiIyXalxZFhEPMAu4AugJTBKRnpVsOldV+zmvFwFUdUnpMrzjjeUAC53t/wz8XVW7AMfxfjGzQWsRE860S85h6V0jeOV/BjOgY3Oe+2wXw2csYcq/VrJ4yyF7uqQxpkHw9wrxNOBOoFhE8vB+8VFVtdkZ9hkM7FTVbwFEZA4wFthczRqvAT5U1Rwn1C4FrnPWvQI8DPyzmm3WSyEhwiXdkrikWxIHMnKZs3IvKav2ccsrq2mbEMV1QzowYVB7WsZGuF2qMcZUyt9QiQeuBzqr6h9EpAPQpop92gK+T4tMwzuEfkXjRWQ4sB24s5InTE4E/uZMJwIZqlo6tnya8z4/ICJTgakASUlJLF26tIpy658B4dDnAg9rD0ewZG8+Mz7ext8WbuP8ZA+XdgijW/OQat+WnJ2d3SD7ojZYX5SzvihnfREYf0NlFlCC9yjhD0AW8DYQ6IO73gNSVDVfRKbhPfK4tHSliLQBegMfV7dhVX0eeB6ge/fuOmLEiABLdc9lwD3AzsPZvL5iD2+tSWPF93l0S47l+iEdGTegLc0iw/xqa+nSpTTkvggm64ty1hflrC8C4/dDulT1diAPQFWPA1VdIN8PtPeZb+csK6OqR1U135l9ERhYoY2fA/NVtdCZPwokiEhpGP6gzcasS6tYHrrqPFb+/jL+Mr4PkWEeHnp3E0MfW8z989azcf8Jt0s0xjRx/h6pFDoX3hVARJLwHrmcySqgq4h0xvuLfyLl10Jw2mmjqqXjw48BtlRoYxJwf+mMqqqILMF7nWUOMBl4x8/P0GhEhXv4+aD2/HxQe9bty+C1r/cwb+1+Ulbuo3+HBG4Y0pEr+7QhMsxuSzbG1C1/j1T+AcwHWonIo8AXwGNn2sG57nEH3lNXW4A3VHWTiPxBRMY4m/1aRDaJyDrg18DNpfuLSCe8RzqfVWj6XuC3IrIT7zWWJj2wZd/2Ccy4ti8rf38Z//fTnpzIKeR3b65j6J8W8+h/N7P7yEm3SzTGNCF+Hamo6usisgYYhffOr6tVteJRRWX7fQB8UGHZgz7T9+NzJFJhu91UchHeuZtssD91NyXx0WHcclFn/ufCTizfdZTXVuxh9pe7eeHz77i4a0uuH9KRy3q0crtMY0wj5/egU6q6Fdhai7WYIBARhnVpybAuLTmUmceclftIWbmX215bQ+tmkXRvVsSBqL30bhtPt9ax9s19Y0xQ2UiGjVhys0imX9aV20eew+Kth5m7ah9f7zzMZ/M3ABDmEbq3jqN323h6tY2nd9t4ureOs6AxxtSYhUoTEOoJ4fLzWnP5ea1ZsmQJ5/QZwob9J5xXBh9s+J6Uld6vB4V5hG7JcfRpZ0FjjKk+C5UmRkTokBhNh8Roruzj/f6qqrLvWG5Z0Gzcf6LSoPE9ojm3jQWNMeaHLFTMaYMm7Xh50GxIO8GHG79nzipv0ISGVH7qzG5jNqZps1AxlRIR2reIpn2LaH7Su/Kg2bj/BB9tOjVoyo5o2jlHNBY0xjQpFirGb2cKmo1l12hO8PHm75m72oLGmKbIQsUExDdorjhD0Cz0CRoRaNMskvYtounQIpqOidE+0zE0jw6r9kCZxpj6wULFBN3pgmZ/hjdotn6fxd5jOew9msNn29M5nJV/yv6xEaFOyETRMTGmPHBaRHNWQhThof4OBGGMqWsWKqZOiAjtmkfTrnk0o3ud+tSE3IJi9h33hszeY+WvXeknWbItnYKi8mHmQgTaxEfRMdEbNO2dI50OTvAkRDfIB4Ea02hYqBjXRYV76JYcR7fkuB+sKylRDmflnxI2e4+eZO+xHBZtOcyR7FOPcppFhnrvZGsRTYcWMWVh0zExmjbxkYR67CjHmNpkoWLqtZAQoXV8JK3jIxncucUP1p/ML6r0KGfr91ks2nyYguLyoxxPiNA2IcobNInRFBwvILP5Ado1j6Jd8yiSYiPsWo4xAbJQMQ1aTEQo57Zuxrmtf/hk6+IS5VBmns8RTnnofLTxe46dLOSt7d+UbR8RGkLbhCjaNo9yTtVF+byiSYqNICTEQseYM7FQMY2WJ0Q4KyGKsxKiGHp24g/Wf7RoCWf3Pp/9x3NJO55D2vFc55XDwgPfc/RkwSnbh3tCnMCJom1CediU/mwVZ6FjjIWKabIiQ+W013IAcgqKOJCRyz6fsNnvTFd2PSfM4w2xds2jaJfgDRvfo57kZpF4LHRMI2ehYsxpRIeH0qVVHF1aVR46uQXF7M9wwiYj95QjnU+3HSa9wq3Soc6Rk+9RTpuESJJiI2gZG0HLuHASYyLslmnToFmoGFNDUeEeurSKpUur2ErX5xUWc6BC2JT+XLYjnUOZ+ZXuFx8VRsvYcCdoIpzQceadZaXzNjKBqW8sVIypJZFhHs5OiuXspNOHzuHMfNKz8zlS+soqKJ/OzmfzgUyOZOeTlVdUaRuxEaEVAsdnOjaCJJ/5mAj7525qn/0tM8YlkWGestGhq5JXWMzRkwUcyfIJoOwC0n3md6Zn8/V3+WTkFFbaRlSYh0SfAPINnIMHi/DsSKd5dDgJ0WE0jw4nOtxjt1ibarNQMaYBiAzzeG93ToiqctvC4hKOnfQNHOfox2c+7XgOqfuOc+xkASXq3e/ZdStPaSfcE1IWMKU/m8eEkRAdTvPo0p/e6eYx3un4qDC7GaGJs1AxppEJ84SQ3CyS5GaRVW5bXKIcO1nAws++pOt5/TieU0BGTgHHcwq90yednzmF7ErP5vge73RRaRJVIALNIsN8Qqc0lJwgivFd5gRVdDhR4XZtqLGwUDGmCfOECElxEbSNDal0xILKqCpZ+UVlgVMaOsedMMrw+Zmenc/2Q9lk5BRwsqD4tG1GhIaUHenER4XRLCqMhOiwsvl4Z76Z77yzXZgNvVOvWKgYY6pFRGgWGUazyDC/rgeVyi8q5kROYflRkO8RkRNCJ3ILycgpJO14DpsPFHIit/CMYQQQE+45QxCF/yCIfIPLTtUFn4WKMaZORIR6aNXMQys/Tsv5KigqITPPGzAncgs5keMz7bwynGWZuYXsPpJDRq43oPIKS87Ydlxk6CkhFB8VRvbxfD7L2kRcRCgxzisuMpSYcJ/piFBinVdkWIjd0ODDQsUYU6+Fh4aU3aVWXflFxX4F0YncQjJyC9lxOJujJ4pJPZJGdkERWvmlo1N4QoSYcI83ZCoEzg+mI0OJjfAQE1467QSV87Mx3HFnoWKMabQiQj20ivPQKs7/o6OlS5cyYsQIVJWcgmJO5heR7fvKK+JkQRHZ+cXeaZ91vtOHMvPIziufP829DacIEYgJD6Vdi2g+nH5xAJ/cPRYqxhhTCREpO/3VKsC2VJW8wpIfho8TUFlOOJ3MLyIrv4iI0IZ7N5yFijHG1DIRISrcQ1S4h6S46p/Ga0jsXjxjjDFBY6FijDEmaET9ub2hgRORLGCb23XUEy2BI24XUU9YX5SzvihnfVGuu6pW/uyH02gq11S2qer5bhdRH4jIausLL+uLctYX5awvyonI6uruY6e/jDHGBI2FijHGmKBpKqHyvNsF1CPWF+WsL8pZX5SzvihX7b5oEhfqjTHG1I2mcqRijDGmDlioGGOMCZpGHSoiMlpEtonIThG5z+163CIi7UVkiYhsFpFNIjLd7ZrcJiIeEflGRN53uxY3iUiCiLwlIltFZIuIXOB2TW4RkTudfx8bRSRFRKo3Rn8DJiKzReSwiGz0WdZCRD4RkR3Oz+b+tNVoQ0VEPMAs4AqgJzBJRHq6W5VrioDfqWpPYChwexPui1LTgS1uF1EPPAl8pKrnAn1pon0iIm2BXwPnq2ovwANMdLeqOvUyMLrCsvuAxaraFVjszFep0YYKMBjYqarfqmoBMAcY63JNrlDVg6q61pnOwvuLo627VblHRNoBVwIvul2Lm0QkHhgOvASgqgWqmuFqUe4KBaJEJBSIBg64XE+dUdVlwLEKi8cCrzjTrwBX+9NWYw6VtsA+n/k0mvAv0lIi0gnoD6xwuRQ3zQTuAc78WMDGrzOQDvzLORX4oojEuF2UG1R1P/AEsBc4CJxQ1YXuVuW6ZFU96Ex/DyT7s1NjDhVTgYjEAm8Dv1HVTLfrcYOI/BQ4rKpr3K6lHggFBgD/VNX+wEn8PMXR2DjXC8biDdqzgBgRucHdquoP9X73xK/vnzTmUNkPtPeZb+csa5JEJAxvoLyuqvPcrsdFFwJjRGQ33lOil4rIa+6W5Jo0IE1VS49a38IbMk3RZcB3qpquqoXAPGCYyzW57ZCItAFwfh72Z6fGHCqrgK4i0llEwvFedHvX5ZpcId6HXr8EbFHVv7ldj5tU9X5VbaeqnfD+nfhUVZvk/0hV9Xtgn4h0dxaNAja7WJKb9gJDRSTa+fcyiiZ604KPd4HJzvRk4B1/dmq0oxSrapGI3AF8jPdOjtmqusnlstxyIXAjsEFEUp1lv1fVD9wrydQTvwJed/7j9S0wxeV6XKGqK0TkLWAt3rslv6EJDdciIinACKCliKQBDwGPA2+IyC3AHuDnfrVlw7QYY4wJlsZ8+ssYY0wds1AxxhgTNBYqxhhjgsZCxRhjTNBYqBhjjAkaCxVjakhEikUk1RnV9j0RSajl97tZRJ6uzfcwJlAWKsbUXK6q9nNGtT0G3O52Qca4zULFmOBYjjNgqYj0E5GvRWS9iMwvfQ6FiCwVkfOd6ZbOUDGlRyDzROQj59kVfyltVESmiMh2EVmJ90uspcuvdY6Q1onIsjr8nMackYWKMQFynt0zivJhgF4F7lXVPsAGvN9Orko/YALQG5jgPFitDfAI3jC5CO9zgUo9CFyuqn2BMcH4HMYEg4WKMTUX5Qx7Uzos+CfOM0oSVPUzZ5tX8D6zpCqLVfWEqubhHX+rIzAEWOoMclgAzPXZ/kvgZRG5Fe8wRMbUCxYqxtRcrqr2wxsAQtXXVIoo/zdX8VG1+T7TxVQxLp+q3gY8gHck7jUikuhnzcbUKgsVYwKkqjl4H0X7O7zPJDkuIhc7q28ESo9adgMDnelr/Gh6BXCJiCQ6jy64tnSFiJyjqitU9UG8D9pqf7pGjKlLjXaUYmPqkqp+IyLrgUl4hwl/VkSiOXXk3yfwjvo6FfivH20eFJGH8d4EkAGk+qyeISJd8R4hLQbWBeeTGBMYG6XYGGNM0NjpL2OMMUFjoWKMMSZoLFSMMcYEjYWKMcaYoLFQMcYYEzQWKsYYY4LGQsUYY0zQ/H8oF6z15/HamgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "# make a little extra space between the subplots\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "s1 = np.array(all_results) #FedProx\n",
    "\n",
    "t = range(0,s1.shape[0])\n",
    "\n",
    "ax1.plot(t, s1[:,0],label='Acc of FedProx')\n",
    "ax1.set_xlim(0,s1.shape[0])\n",
    "ax1.set_xlabel('Rounds')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_ylim(0.98,1)\n",
    "ax1.grid(True)\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2.plot(t, s1[:,1],label='Error of FedProx')\n",
    "ax2.set_xlim(0, s1.shape[0])\n",
    "ax2.set_xlabel('Rounds')\n",
    "ax2.set_ylabel('error')\n",
    "ax2.grid(True)\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3861d31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b54df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55b69fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "173907af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from federated_utils_fedavg_copy import *\n",
    "\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4bf76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declear path to your data\n",
    "drebin_data_path = r'data\\drebin.csv'\n",
    "malgenome_data_path = r'data\\malgenome.csv'\n",
    "kronodroid_data_path = r'data\\kronodroid.csv'\n",
    "TUANDROMD_data_path=r'data\\TUANDROMD.csv'\n",
    "\n",
    "\n",
    "\n",
    "Drebin_data = pd.read_csv(drebin_data_path, header = None)\n",
    "\n",
    "Malgenome_data = pd.read_csv(malgenome_data_path)\n",
    "\n",
    "Tuandromd_data=pd.read_csv(TUANDROMD_data_path)\n",
    "\n",
    "kronodroid_data=pd.read_csv(kronodroid_data_path)\n",
    "Kronodroid_data = kronodroid_data.iloc[:,range(1,kronodroid_data.shape[1])]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da6c9299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================\n",
      "Working with: Drebin\n",
      "===================================================================================================\n",
      "---------------------------------------------\n",
      "No. of Clients: 5\n",
      "No. of Rounds: 200\n",
      "---------------------------------------------\n",
      "|=======================|\n",
      "|Traditional FedAvg 2017|\n",
      "|=======================|\n",
      "comm_round: 0 | global_acc: 63.132% | global_loss: 0.6576090455055237 | global_f1: 0.0 | global_precision: 1.0 | global_recall: 0.0 | global_auc: 0.7293502203950539| flobal_FPR: 1.0 \n",
      "comm_round: 1 | global_acc: 63.132% | global_loss: 0.6364310383796692 | global_f1: 0.0 | global_precision: 1.0 | global_recall: 0.0 | global_auc: 0.8084820875302886| flobal_FPR: 1.0 \n",
      "comm_round: 2 | global_acc: 63.132% | global_loss: 0.6089396476745605 | global_f1: 0.0 | global_precision: 1.0 | global_recall: 0.0 | global_auc: 0.8591651151405679| flobal_FPR: 1.0 \n",
      "comm_round: 3 | global_acc: 63.132% | global_loss: 0.567911684513092 | global_f1: 0.0 | global_precision: 1.0 | global_recall: 0.0 | global_auc: 0.8994195606723865| flobal_FPR: 1.0 \n",
      "comm_round: 4 | global_acc: 63.630% | global_loss: 0.5124006271362305 | global_f1: 0.026690391459074734 | global_precision: 1.0 | global_recall: 0.013525698827772768 | global_auc: 0.9351644902566061| flobal_FPR: 0.9864743011722272 \n",
      "comm_round: 5 | global_acc: 81.616% | global_loss: 0.4489056169986725 | global_f1: 0.6686638705811864 | global_precision: 0.9964285714285714 | global_recall: 0.503155996393147 | global_auc: 0.9636983253964524| flobal_FPR: 0.49684400360685305 \n",
      "comm_round: 6 | global_acc: 90.891% | global_loss: 0.3807717263698578 | global_f1: 0.8610547667342798 | global_precision: 0.9837775202780996 | global_recall: 0.7655545536519387 | global_auc: 0.9772999979582059| flobal_FPR: 0.2344454463480613 \n",
      "comm_round: 7 | global_acc: 94.149% | global_loss: 0.30826643109321594 | global_f1: 0.916030534351145 | global_precision: 0.9726443768996961 | global_recall: 0.8656447249774571 | global_auc: 0.9841699228534214| flobal_FPR: 0.13435527502254282 \n",
      "comm_round: 8 | global_acc: 95.013% | global_loss: 0.2398231327533722 | global_f1: 0.9302973977695168 | global_precision: 0.959731543624161 | global_recall: 0.9026149684400361 | global_auc: 0.9871951019733702| flobal_FPR: 0.09738503155996393 \n",
      "comm_round: 9 | global_acc: 95.246% | global_loss: 0.18769532442092896 | global_f1: 0.9338881183541378 | global_precision: 0.9582542694497154 | global_recall: 0.9107303877366997 | global_auc: 0.9890156225738856| flobal_FPR: 0.08926961226330027 \n",
      "comm_round: 10 | global_acc: 95.445% | global_loss: 0.15438459813594818 | global_f1: 0.9370114942528736 | global_precision: 0.9559099437148217 | global_recall: 0.9188458070333634 | global_auc: 0.990395020681475| flobal_FPR: 0.0811541929666366 \n",
      "comm_round: 11 | global_acc: 96.110% | global_loss: 0.1332062929868698 | global_f1: 0.9464530892448513 | global_precision: 0.9609665427509294 | global_recall: 0.9323715058611362 | global_auc: 0.9914273137919392| flobal_FPR: 0.06762849413886383 \n",
      "comm_round: 12 | global_acc: 96.310% | global_loss: 0.11930590122938156 | global_f1: 0.9492455418381345 | global_precision: 0.9628942486085343 | global_recall: 0.9359783588818755 | global_auc: 0.9921775544149998| flobal_FPR: 0.06402164111812443 \n",
      "comm_round: 13 | global_acc: 96.576% | global_loss: 0.11001298576593399 | global_f1: 0.9531605275125056 | global_precision: 0.9614678899082569 | global_recall: 0.9449954914337241 | global_auc: 0.9928233311538367| flobal_FPR: 0.05500450856627592 \n",
      "comm_round: 14 | global_acc: 96.809% | global_loss: 0.10293249040842056 | global_f1: 0.9561643835616438 | global_precision: 0.9685476410730804 | global_recall: 0.9440937781785392 | global_auc: 0.9932202939138867| flobal_FPR: 0.05590622182146077 \n",
      "comm_round: 15 | global_acc: 96.975% | global_loss: 0.09761860221624374 | global_f1: 0.9585798816568047 | global_precision: 0.9678308823529411 | global_recall: 0.9495040577096483 | global_auc: 0.9936357752715943| flobal_FPR: 0.05049594229035167 \n",
      "comm_round: 16 | global_acc: 97.207% | global_loss: 0.09352003037929535 | global_f1: 0.9617834394904459 | global_precision: 0.970615243342516 | global_recall: 0.9531109107303878 | global_auc: 0.9939092807139253| flobal_FPR: 0.046889089269612265 \n",
      "comm_round: 17 | global_acc: 97.074% | global_loss: 0.09044501185417175 | global_f1: 0.9601087941976428 | global_precision: 0.9653600729261622 | global_recall: 0.9549143372407575 | global_auc: 0.9941452741251031| flobal_FPR: 0.04508566275924256 \n",
      "comm_round: 18 | global_acc: 97.274% | global_loss: 0.08753642439842224 | global_f1: 0.9626253418413857 | global_precision: 0.9732718894009217 | global_recall: 0.9522091974752029 | global_auc: 0.9943565760727372| flobal_FPR: 0.047790802524797116 \n",
      "comm_round: 19 | global_acc: 97.241% | global_loss: 0.08538702875375748 | global_f1: 0.9623241034952338 | global_precision: 0.9689213893967094 | global_recall: 0.9558160504959423 | global_auc: 0.994551258766063| flobal_FPR: 0.04418394950405771 \n",
      "comm_round: 20 | global_acc: 97.307% | global_loss: 0.0833834707736969 | global_f1: 0.9631650750341064 | global_precision: 0.9715596330275229 | global_recall: 0.9549143372407575 | global_auc: 0.9947207751600078| flobal_FPR: 0.04508566275924256 \n",
      "comm_round: 21 | global_acc: 97.241% | global_loss: 0.08214732259511948 | global_f1: 0.9623923878568192 | global_precision: 0.9672131147540983 | global_recall: 0.957619477006312 | global_auc: 0.9949211558833823| flobal_FPR: 0.04238052299368801 \n",
      "comm_round: 22 | global_acc: 97.473% | global_loss: 0.08021122217178345 | global_f1: 0.9653600729261622 | global_precision: 0.976036866359447 | global_recall: 0.9549143372407575 | global_auc: 0.9950256197676057| flobal_FPR: 0.04508566275924256 \n",
      "comm_round: 23 | global_acc: 97.507% | global_loss: 0.07881443947553635 | global_f1: 0.9658625398270368 | global_precision: 0.9751838235294118 | global_recall: 0.9567177637511272 | global_auc: 0.995145753234463| flobal_FPR: 0.04328223624887286 \n",
      "comm_round: 24 | global_acc: 97.440% | global_loss: 0.07799030840396881 | global_f1: 0.9650793650793651 | global_precision: 0.9708029197080292 | global_recall: 0.9594229035166817 | global_auc: 0.9952801317764417| flobal_FPR: 0.0405770964833183 \n",
      "comm_round: 25 | global_acc: 97.540% | global_loss: 0.07676005363464355 | global_f1: 0.9664246823956443 | global_precision: 0.9726027397260274 | global_recall: 0.9603246167718665 | global_auc: 0.9953679764063569| flobal_FPR: 0.03967538322813345 \n",
      "comm_round: 26 | global_acc: 97.606% | global_loss: 0.07584863156080246 | global_f1: 0.9673321234119783 | global_precision: 0.9735159817351599 | global_recall: 0.9612263300270514 | global_auc: 0.9954297050652163| flobal_FPR: 0.0387736699729486 \n",
      "comm_round: 27 | global_acc: 97.739% | global_loss: 0.07487472891807556 | global_f1: 0.9690627843494085 | global_precision: 0.977961432506887 | global_recall: 0.9603246167718665 | global_auc: 0.9955033046200102| flobal_FPR: 0.03967538322813345 \n",
      "comm_round: 28 | global_acc: 97.706% | global_loss: 0.07408878952264786 | global_f1: 0.968593536640874 | global_precision: 0.9779411764705882 | global_recall: 0.9594229035166817 | global_auc: 0.9955389173078137| flobal_FPR: 0.0405770964833183 \n",
      "comm_round: 29 | global_acc: 97.739% | global_loss: 0.07336316257715225 | global_f1: 0.969090909090909 | global_precision: 0.9770852428964253 | global_recall: 0.9612263300270514 | global_auc: 0.9956182148926562| flobal_FPR: 0.0387736699729486 \n",
      "comm_round: 30 | global_acc: 97.706% | global_loss: 0.07316482067108154 | global_f1: 0.9687358405074762 | global_precision: 0.9735883424408015 | global_recall: 0.9639314697926059 | global_auc: 0.9956951382983117| flobal_FPR: 0.03606853020739405 \n",
      "comm_round: 31 | global_acc: 97.739% | global_loss: 0.07215286791324615 | global_f1: 0.969090909090909 | global_precision: 0.9770852428964253 | global_recall: 0.9612263300270514 | global_auc: 0.995707958865921| flobal_FPR: 0.0387736699729486 \n",
      "comm_round: 32 | global_acc: 97.739% | global_loss: 0.0717238038778305 | global_f1: 0.9690627843494085 | global_precision: 0.977961432506887 | global_recall: 0.9603246167718665 | global_auc: 0.9957587663005207| flobal_FPR: 0.03967538322813345 \n",
      "comm_round: 33 | global_acc: 97.806% | global_loss: 0.07111155241727829 | global_f1: 0.9699727024567788 | global_precision: 0.9788797061524335 | global_recall: 0.9612263300270514 | global_auc: 0.9957920048091374| flobal_FPR: 0.0387736699729486 \n",
      "comm_round: 34 | global_acc: 97.806% | global_loss: 0.07091205567121506 | global_f1: 0.9700544464609802 | global_precision: 0.9762557077625571 | global_recall: 0.9639314697926059 | global_auc: 0.9958413877362248| flobal_FPR: 0.03606853020739405 \n",
      "comm_round: 35 | global_acc: 97.839% | global_loss: 0.07048685103654861 | global_f1: 0.9704947798456649 | global_precision: 0.9771480804387569 | global_recall: 0.9639314697926059 | global_auc: 0.9958646546922564| flobal_FPR: 0.03606853020739405 \n",
      "comm_round: 36 | global_acc: 97.906% | global_loss: 0.07019555568695068 | global_f1: 0.9714285714285713 | global_precision: 0.9771897810218978 | global_recall: 0.9657348963029756 | global_auc: 0.9959145124551814| flobal_FPR: 0.034265103697024346 \n",
      "comm_round: 37 | global_acc: 97.906% | global_loss: 0.06990236043930054 | global_f1: 0.9714026327734907 | global_precision: 0.9780621572212066 | global_recall: 0.9648331830477908 | global_auc: 0.9959078647534582| flobal_FPR: 0.0351668169522092 \n",
      "comm_round: 38 | global_acc: 97.872% | global_loss: 0.06954493373632431 | global_f1: 0.9709355131698456 | global_precision: 0.9780420860018298 | global_recall: 0.9639314697926059 | global_auc: 0.9959729172631792| flobal_FPR: 0.03606853020739405 \n",
      "comm_round: 39 | global_acc: 98.039% | global_loss: 0.07000046223402023 | global_f1: 0.9733152419719584 | global_precision: 0.9764065335753176 | global_recall: 0.9702434625788999 | global_auc: 0.9959354052320262| flobal_FPR: 0.029756537421100092 \n",
      "comm_round: 40 | global_acc: 98.005% | global_loss: 0.06908702105283737 | global_f1: 0.9728014505893019 | global_precision: 0.9781221513217867 | global_recall: 0.9675383228133454 | global_auc: 0.9959900113533249| flobal_FPR: 0.032461677186654644 \n",
      "comm_round: 41 | global_acc: 97.839% | global_loss: 0.06879453361034393 | global_f1: 0.9704679691049523 | global_precision: 0.978021978021978 | global_recall: 0.9630297565374211 | global_auc: 0.9959980835625604| flobal_FPR: 0.0369702434625789 \n",
      "comm_round: 42 | global_acc: 98.105% | global_loss: 0.06895910948514938 | global_f1: 0.9742198100407056 | global_precision: 0.9773139745916516 | global_recall: 0.9711451758340848 | global_auc: 0.9960545890272086| flobal_FPR: 0.028854824165915238 \n",
      "comm_round: 43 | global_acc: 98.072% | global_loss: 0.06861220300197601 | global_f1: 0.9737318840579711 | global_precision: 0.978161965423112 | global_recall: 0.9693417493237151 | global_auc: 0.9960536393555338| flobal_FPR: 0.030658250676284943 \n",
      "comm_round: 44 | global_acc: 98.039% | global_loss: 0.06833789497613907 | global_f1: 0.9732668781150884 | global_precision: 0.9781420765027322 | global_recall: 0.9684400360685302 | global_auc: 0.9960484161613226| flobal_FPR: 0.031559963931469794 \n",
      "comm_round: 45 | global_acc: 98.005% | global_loss: 0.06813102215528488 | global_f1: 0.9727520435967303 | global_precision: 0.979871912168344 | global_recall: 0.9657348963029756 | global_auc: 0.9960754818040531| flobal_FPR: 0.034265103697024346 \n",
      "comm_round: 46 | global_acc: 98.138% | global_loss: 0.06805046647787094 | global_f1: 0.9745916515426496 | global_precision: 0.9808219178082191 | global_recall: 0.9684400360685302 | global_auc: 0.9961068209693205| flobal_FPR: 0.031559963931469794 \n",
      "comm_round: 47 | global_acc: 98.172% | global_loss: 0.0679273009300232 | global_f1: 0.9750792931581332 | global_precision: 0.9799635701275046 | global_recall: 0.9702434625788999 | global_auc: 0.9961334117762136| flobal_FPR: 0.029756537421100092 \n",
      "comm_round: 48 | global_acc: 98.138% | global_loss: 0.06824152171611786 | global_f1: 0.9746376811594203 | global_precision: 0.9790718835304822 | global_recall: 0.9702434625788999 | global_auc: 0.9961799456882768| flobal_FPR: 0.029756537421100092 \n",
      "comm_round: 49 | global_acc: 98.172% | global_loss: 0.06776964664459229 | global_f1: 0.9750792931581332 | global_precision: 0.9799635701275046 | global_recall: 0.9702434625788999 | global_auc: 0.9961899172408619| flobal_FPR: 0.029756537421100092 \n",
      "comm_round: 50 | global_acc: 98.172% | global_loss: 0.067566879093647 | global_f1: 0.9750566893424036 | global_precision: 0.9808394160583942 | global_recall: 0.9693417493237151 | global_auc: 0.9961970397784227| flobal_FPR: 0.030658250676284943 \n",
      "comm_round: 51 | global_acc: 98.138% | global_loss: 0.06771066039800644 | global_f1: 0.9746146872166819 | global_precision: 0.9799453053783045 | global_recall: 0.9693417493237151 | global_auc: 0.9962321776303888| flobal_FPR: 0.030658250676284943 \n",
      "comm_round: 52 | global_acc: 98.072% | global_loss: 0.06757912784814835 | global_f1: 0.9736603088101726 | global_precision: 0.9807868252516011 | global_recall: 0.9666366095581606 | global_auc: 0.9962250550928281| flobal_FPR: 0.033363390441839495 \n",
      "comm_round: 53 | global_acc: 98.138% | global_loss: 0.06761565059423447 | global_f1: 0.9746146872166819 | global_precision: 0.9799453053783045 | global_recall: 0.9693417493237151 | global_auc: 0.9962426240188111| flobal_FPR: 0.030658250676284943 \n",
      "comm_round: 54 | global_acc: 98.172% | global_loss: 0.0677853524684906 | global_f1: 0.9751018560434586 | global_precision: 0.9790909090909091 | global_recall: 0.9711451758340848 | global_auc: 0.9962658909748427| flobal_FPR: 0.028854824165915238 \n",
      "comm_round: 55 | global_acc: 98.105% | global_loss: 0.06739618629217148 | global_f1: 0.9741496598639456 | global_precision: 0.9799270072992701 | global_recall: 0.9684400360685302 | global_auc: 0.9962606677806316| flobal_FPR: 0.031559963931469794 \n",
      "comm_round: 56 | global_acc: 98.205% | global_loss: 0.06732042133808136 | global_f1: 0.9755434782608696 | global_precision: 0.9799818016378526 | global_recall: 0.9711451758340848 | global_auc: 0.9962639916314932| flobal_FPR: 0.028854824165915238 \n",
      "comm_round: 57 | global_acc: 98.172% | global_loss: 0.0674121305346489 | global_f1: 0.9750792931581332 | global_precision: 0.9799635701275046 | global_recall: 0.9702434625788999 | global_auc: 0.9962858340800127| flobal_FPR: 0.029756537421100092 \n",
      "comm_round: 58 | global_acc: 98.072% | global_loss: 0.06722825765609741 | global_f1: 0.9736842105263159 | global_precision: 0.9799086757990868 | global_recall: 0.9675383228133454 | global_auc: 0.9962891579308744| flobal_FPR: 0.032461677186654644 \n",
      "comm_round: 59 | global_acc: 98.172% | global_loss: 0.0673559308052063 | global_f1: 0.9750792931581332 | global_precision: 0.9799635701275046 | global_recall: 0.9702434625788999 | global_auc: 0.9963228712753284| flobal_FPR: 0.029756537421100092 \n",
      "comm_round: 60 | global_acc: 98.072% | global_loss: 0.06729454547166824 | global_f1: 0.9736842105263159 | global_precision: 0.9799086757990868 | global_recall: 0.9675383228133454 | global_auc: 0.9963252454545153| flobal_FPR: 0.032461677186654644 \n",
      "comm_round: 61 | global_acc: 98.172% | global_loss: 0.06737091392278671 | global_f1: 0.9750792931581332 | global_precision: 0.9799635701275046 | global_recall: 0.9702434625788999 | global_auc: 0.9963437640521732| flobal_FPR: 0.029756537421100092 \n",
      "comm_round: 62 | global_acc: 98.205% | global_loss: 0.06751396507024765 | global_f1: 0.9755434782608696 | global_precision: 0.9799818016378526 | global_recall: 0.9711451758340848 | global_auc: 0.9963665561723675| flobal_FPR: 0.028854824165915238 \n",
      "comm_round: 63 | global_acc: 98.138% | global_loss: 0.06740230321884155 | global_f1: 0.974568574023615 | global_precision: 0.9817017383348582 | global_recall: 0.9675383228133454 | global_auc: 0.9963290441412143| flobal_FPR: 0.032461677186654644 \n",
      "comm_round: 64 | global_acc: 98.238% | global_loss: 0.06775883585214615 | global_f1: 0.9760289461781999 | global_precision: 0.9791288566243194 | global_recall: 0.9729486023444545 | global_auc: 0.9963921973075858| flobal_FPR: 0.027051397655545536 \n",
      "comm_round: 65 | global_acc: 98.238% | global_loss: 0.06760796904563904 | global_f1: 0.9760072430964237 | global_precision: 0.98 | global_recall: 0.9720468890892696 | global_auc: 0.9963888734567241| flobal_FPR: 0.027953110910730387 \n",
      "comm_round: 66 | global_acc: 98.271% | global_loss: 0.06805742532014847 | global_f1: 0.976491862567812 | global_precision: 0.9791477787851315 | global_recall: 0.9738503155996393 | global_auc: 0.9964463285930472| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 67 | global_acc: 98.238% | global_loss: 0.06776724755764008 | global_f1: 0.9760289461781999 | global_precision: 0.9791288566243194 | global_recall: 0.9729486023444545 | global_auc: 0.99643493253295| flobal_FPR: 0.027051397655545536 \n",
      "comm_round: 68 | global_acc: 98.205% | global_loss: 0.06750781089067459 | global_f1: 0.9754990925589837 | global_precision: 0.9817351598173516 | global_recall: 0.9693417493237151 | global_auc: 0.9964306590104136| flobal_FPR: 0.030658250676284943 \n",
      "comm_round: 69 | global_acc: 98.205% | global_loss: 0.067788265645504 | global_f1: 0.9755656108597286 | global_precision: 0.9791099000908265 | global_recall: 0.9720468890892696 | global_auc: 0.9964544008022826| flobal_FPR: 0.027953110910730387 \n",
      "comm_round: 70 | global_acc: 98.271% | global_loss: 0.06759094446897507 | global_f1: 0.9764279238440617 | global_precision: 0.9817684594348223 | global_recall: 0.9711451758340848 | global_auc: 0.9964529762947705| flobal_FPR: 0.028854824165915238 \n",
      "comm_round: 71 | global_acc: 98.271% | global_loss: 0.06864666938781738 | global_f1: 0.976513098464318 | global_precision: 0.9782805429864253 | global_recall: 0.9747520288548241 | global_auc: 0.996457249817307| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 72 | global_acc: 98.305% | global_loss: 0.06887006014585495 | global_f1: 0.9769959404600811 | global_precision: 0.9774368231046932 | global_recall: 0.9765554553651938 | global_auc: 0.9964577246531442| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 73 | global_acc: 98.305% | global_loss: 0.06784570217132568 | global_f1: 0.9769335142469472 | global_precision: 0.9800362976406534 | global_recall: 0.9738503155996393 | global_auc: 0.9964705452207536| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 74 | global_acc: 98.371% | global_loss: 0.06790218502283096 | global_f1: 0.9778581111613194 | global_precision: 0.980072463768116 | global_recall: 0.975653742110009 | global_auc: 0.9964662716982171| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 75 | global_acc: 98.305% | global_loss: 0.06787563115358353 | global_f1: 0.9769126301493889 | global_precision: 0.980909090909091 | global_recall: 0.9729486023444545 | global_auc: 0.9964415802346734| flobal_FPR: 0.027051397655545536 \n",
      "comm_round: 76 | global_acc: 98.305% | global_loss: 0.06802130490541458 | global_f1: 0.9768707482993196 | global_precision: 0.9826642335766423 | global_recall: 0.9711451758340848 | global_auc: 0.9964316086820884| flobal_FPR: 0.028854824165915238 \n",
      "comm_round: 77 | global_acc: 98.371% | global_loss: 0.06854844838380814 | global_f1: 0.9778581111613194 | global_precision: 0.980072463768116 | global_recall: 0.975653742110009 | global_auc: 0.9964786174299889| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 78 | global_acc: 98.404% | global_loss: 0.06840460002422333 | global_f1: 0.978319783197832 | global_precision: 0.9800904977375565 | global_recall: 0.9765554553651938 | global_auc: 0.9964719697282656| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 79 | global_acc: 98.404% | global_loss: 0.06849031895399094 | global_f1: 0.978319783197832 | global_precision: 0.9800904977375565 | global_recall: 0.9765554553651938 | global_auc: 0.9964776677583144| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 80 | global_acc: 98.404% | global_loss: 0.06864187866449356 | global_f1: 0.978319783197832 | global_precision: 0.9800904977375565 | global_recall: 0.9765554553651938 | global_auc: 0.9964828909525254| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 81 | global_acc: 98.305% | global_loss: 0.0684959813952446 | global_f1: 0.9769335142469472 | global_precision: 0.9800362976406534 | global_recall: 0.9738503155996393 | global_auc: 0.9964724445641031| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 82 | global_acc: 98.305% | global_loss: 0.06850066781044006 | global_f1: 0.9769335142469472 | global_precision: 0.9800362976406534 | global_recall: 0.9738503155996393 | global_auc: 0.9964714948924283| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 83 | global_acc: 98.371% | global_loss: 0.06847067922353745 | global_f1: 0.9777979157227006 | global_precision: 0.982695810564663 | global_recall: 0.9729486023444545 | global_auc: 0.9964624730115181| flobal_FPR: 0.027051397655545536 \n",
      "comm_round: 84 | global_acc: 98.338% | global_loss: 0.06862224638462067 | global_f1: 0.9773139745916515 | global_precision: 0.9835616438356164 | global_recall: 0.9711451758340848 | global_auc: 0.996458674324819| flobal_FPR: 0.028854824165915238 \n",
      "comm_round: 85 | global_acc: 98.338% | global_loss: 0.06875921040773392 | global_f1: 0.9773139745916515 | global_precision: 0.9835616438356164 | global_recall: 0.9711451758340848 | global_auc: 0.996463422683193| flobal_FPR: 0.028854824165915238 \n",
      "comm_round: 86 | global_acc: 98.338% | global_loss: 0.0688064694404602 | global_f1: 0.9773550724637681 | global_precision: 0.9818016378525932 | global_recall: 0.9729486023444545 | global_auc: 0.9964871644750619| flobal_FPR: 0.027051397655545536 \n",
      "comm_round: 87 | global_acc: 98.338% | global_loss: 0.0694127082824707 | global_f1: 0.9772933696639419 | global_precision: 0.9844464775846294 | global_recall: 0.9702434625788999 | global_auc: 0.9964487027722341| flobal_FPR: 0.029756537421100092 \n",
      "comm_round: 88 | global_acc: 98.338% | global_loss: 0.0689268708229065 | global_f1: 0.9773139745916515 | global_precision: 0.9835616438356164 | global_recall: 0.9711451758340848 | global_auc: 0.9965004598785085| flobal_FPR: 0.028854824165915238 \n",
      "comm_round: 89 | global_acc: 98.371% | global_loss: 0.06908070296049118 | global_f1: 0.9778380823156942 | global_precision: 0.9809437386569873 | global_recall: 0.9747520288548241 | global_auc: 0.9964695955490788| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 90 | global_acc: 98.371% | global_loss: 0.06907618045806885 | global_f1: 0.9778380823156942 | global_precision: 0.9809437386569873 | global_recall: 0.9747520288548241 | global_auc: 0.9964619981756807| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 91 | global_acc: 98.438% | global_loss: 0.06919359415769577 | global_f1: 0.978704123244223 | global_precision: 0.9836065573770492 | global_recall: 0.9738503155996393 | global_auc: 0.9964957115201347| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 92 | global_acc: 98.404% | global_loss: 0.0693264752626419 | global_f1: 0.9782805429864253 | global_precision: 0.9818346957311535 | global_recall: 0.9747520288548241 | global_auc: 0.9964710200565909| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 93 | global_acc: 98.338% | global_loss: 0.07052112370729446 | global_f1: 0.9774774774774774 | global_precision: 0.9765976597659766 | global_recall: 0.9783588818755635 | global_auc: 0.996502359221858| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 94 | global_acc: 98.338% | global_loss: 0.0695074126124382 | global_f1: 0.9773755656108598 | global_precision: 0.9809264305177112 | global_recall: 0.9738503155996393 | global_auc: 0.9964752935791273| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 95 | global_acc: 98.438% | global_loss: 0.06962339580059052 | global_f1: 0.9787618617261635 | global_precision: 0.9809782608695652 | global_recall: 0.9765554553651938 | global_auc: 0.9964819412808507| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 96 | global_acc: 98.172% | global_loss: 0.07164653390645981 | global_f1: 0.9749430523917996 | global_precision: 0.9852670349907919 | global_recall: 0.9648331830477908 | global_auc: 0.9963917224717485| flobal_FPR: 0.0351668169522092 \n",
      "comm_round: 97 | global_acc: 98.471% | global_loss: 0.06961437314748764 | global_f1: 0.9792043399638336 | global_precision: 0.9818676337262012 | global_recall: 0.9765554553651938 | global_auc: 0.9964577246531443| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 98 | global_acc: 98.438% | global_loss: 0.06983710080385208 | global_f1: 0.9787618617261635 | global_precision: 0.9809782608695652 | global_recall: 0.9765554553651938 | global_auc: 0.9964952366842973| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 99 | global_acc: 98.404% | global_loss: 0.0697421282529831 | global_f1: 0.9783001808318263 | global_precision: 0.9809610154125114 | global_recall: 0.975653742110009 | global_auc: 0.9964971360276469| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 100 | global_acc: 98.504% | global_loss: 0.06974033266305923 | global_f1: 0.9796287913082843 | global_precision: 0.9836363636363636 | global_recall: 0.975653742110009 | global_auc: 0.9964824161166881| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 101 | global_acc: 98.438% | global_loss: 0.07055649906396866 | global_f1: 0.9788001804239964 | global_precision: 0.9792418772563177 | global_recall: 0.9783588818755635 | global_auc: 0.9964790922658264| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 102 | global_acc: 98.438% | global_loss: 0.07015708088874817 | global_f1: 0.9787618617261635 | global_precision: 0.9809782608695652 | global_recall: 0.9765554553651938 | global_auc: 0.9965073449981505| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 103 | global_acc: 98.471% | global_loss: 0.07022663205862045 | global_f1: 0.9791666666666666 | global_precision: 0.9836214740673339 | global_recall: 0.9747520288548241 | global_auc: 0.996512330774443| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 104 | global_acc: 98.504% | global_loss: 0.0703510195016861 | global_f1: 0.9796103307657453 | global_precision: 0.9845173041894353 | global_recall: 0.9747520288548241 | global_auc: 0.9964733942357779| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 105 | global_acc: 98.371% | global_loss: 0.07248146831989288 | global_f1: 0.9779179810725552 | global_precision: 0.9774774774774775 | global_recall: 0.9783588818755635 | global_auc: 0.996454163384364| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 106 | global_acc: 98.438% | global_loss: 0.07080202549695969 | global_f1: 0.9786654561960964 | global_precision: 0.9853747714808044 | global_recall: 0.9720468890892696 | global_auc: 0.9964762432508021| flobal_FPR: 0.027953110910730387 \n",
      "comm_round: 107 | global_acc: 98.537% | global_loss: 0.0706915333867073 | global_f1: 0.9800724637681161 | global_precision: 0.9845313921747043 | global_recall: 0.975653742110009 | global_auc: 0.9964553504739574| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 108 | global_acc: 98.438% | global_loss: 0.07085318118333817 | global_f1: 0.9786654561960964 | global_precision: 0.9853747714808044 | global_recall: 0.9720468890892696 | global_auc: 0.9964938121767851| flobal_FPR: 0.027953110910730387 \n",
      "comm_round: 109 | global_acc: 98.438% | global_loss: 0.07094551622867584 | global_f1: 0.9786654561960964 | global_precision: 0.9853747714808044 | global_recall: 0.9720468890892696 | global_auc: 0.9964776677583143| flobal_FPR: 0.027953110910730387 \n",
      "comm_round: 110 | global_acc: 98.570% | global_loss: 0.07083466649055481 | global_f1: 0.9805165382872677 | global_precision: 0.9854280510018215 | global_recall: 0.975653742110009 | global_auc: 0.9964966611918096| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 111 | global_acc: 98.504% | global_loss: 0.0710037499666214 | global_f1: 0.9795918367346939 | global_precision: 0.9854014598540146 | global_recall: 0.9738503155996393 | global_auc: 0.9964482279363968| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 112 | global_acc: 98.504% | global_loss: 0.07109978049993515 | global_f1: 0.9796472184531885 | global_precision: 0.9827586206896551 | global_recall: 0.9765554553651938 | global_auc: 0.9964714948924284| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 113 | global_acc: 98.537% | global_loss: 0.07123163342475891 | global_f1: 0.9800724637681161 | global_precision: 0.9845313921747043 | global_recall: 0.975653742110009 | global_auc: 0.9964681710415667| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 114 | global_acc: 98.537% | global_loss: 0.07129713892936707 | global_f1: 0.9800543970988214 | global_precision: 0.9854147675478578 | global_recall: 0.9747520288548241 | global_auc: 0.996463422683193| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 115 | global_acc: 98.604% | global_loss: 0.07140157371759415 | global_f1: 0.9809782608695652 | global_precision: 0.9854413102820746 | global_recall: 0.9765554553651938 | global_auc: 0.9964767180866394| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 116 | global_acc: 98.604% | global_loss: 0.07156804949045181 | global_f1: 0.9809782608695652 | global_precision: 0.9854413102820746 | global_recall: 0.9765554553651938 | global_auc: 0.9964767180866396| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 117 | global_acc: 98.504% | global_loss: 0.07165875285863876 | global_f1: 0.9795918367346939 | global_precision: 0.9854014598540146 | global_recall: 0.9738503155996393 | global_auc: 0.9965014095501833| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 118 | global_acc: 98.471% | global_loss: 0.07295011729001999 | global_f1: 0.9792605951307484 | global_precision: 0.9792605951307484 | global_recall: 0.9792605951307484 | global_auc: 0.9965028340576955| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 119 | global_acc: 98.537% | global_loss: 0.07159673422574997 | global_f1: 0.9800543970988214 | global_precision: 0.9854147675478578 | global_recall: 0.9747520288548241 | global_auc: 0.996463422683193| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 120 | global_acc: 98.604% | global_loss: 0.07168193906545639 | global_f1: 0.9809782608695652 | global_precision: 0.9854413102820746 | global_recall: 0.9765554553651938 | global_auc: 0.9964657968623798| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 121 | global_acc: 98.637% | global_loss: 0.07184794545173645 | global_f1: 0.9814395654142146 | global_precision: 0.9854545454545455 | global_recall: 0.9774571686203787 | global_auc: 0.9964729193999404| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 122 | global_acc: 98.305% | global_loss: 0.07454843819141388 | global_f1: 0.9770580296896085 | global_precision: 0.9748653500897666 | global_recall: 0.9792605951307484 | global_auc: 0.9965075824160692| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 123 | global_acc: 98.305% | global_loss: 0.07427134364843369 | global_f1: 0.9770580296896085 | global_precision: 0.9748653500897666 | global_recall: 0.9792605951307484 | global_auc: 0.9965132804461178| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 124 | global_acc: 98.637% | global_loss: 0.07199393212795258 | global_f1: 0.9814731134206959 | global_precision: 0.9836956521739131 | global_recall: 0.9792605951307484 | global_auc: 0.9964776677583144| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 125 | global_acc: 98.637% | global_loss: 0.07246555387973785 | global_f1: 0.9814898419864561 | global_precision: 0.9828209764918626 | global_recall: 0.9801623083859333 | global_auc: 0.9965109062669308| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 126 | global_acc: 98.604% | global_loss: 0.07218587398529053 | global_f1: 0.9809782608695652 | global_precision: 0.9854413102820746 | global_recall: 0.9765554553651938 | global_auc: 0.9964819412808507| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 127 | global_acc: 98.637% | global_loss: 0.07232196629047394 | global_f1: 0.9814395654142146 | global_precision: 0.9854545454545455 | global_recall: 0.9774571686203787 | global_auc: 0.9964786174299891| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 128 | global_acc: 98.537% | global_loss: 0.07251224666833878 | global_f1: 0.9800543970988214 | global_precision: 0.9854147675478578 | global_recall: 0.9747520288548241 | global_auc: 0.9964657968623798| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 129 | global_acc: 98.637% | global_loss: 0.07249356806278229 | global_f1: 0.9814395654142146 | global_precision: 0.9854545454545455 | global_recall: 0.9774571686203787 | global_auc: 0.9964885889825739| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 130 | global_acc: 98.604% | global_loss: 0.07288658618927002 | global_f1: 0.9810298102981029 | global_precision: 0.9828054298642533 | global_recall: 0.9792605951307484 | global_auc: 0.996524676506215| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 131 | global_acc: 98.637% | global_loss: 0.07275650650262833 | global_f1: 0.9814563545906829 | global_precision: 0.984573502722323 | global_recall: 0.9783588818755635 | global_auc: 0.9964843154600375| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 132 | global_acc: 98.604% | global_loss: 0.07305530458688736 | global_f1: 0.9810298102981029 | global_precision: 0.9828054298642533 | global_recall: 0.9792605951307484 | global_auc: 0.9964942870126225| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 133 | global_acc: 98.604% | global_loss: 0.07303959131240845 | global_f1: 0.9810126582278481 | global_precision: 0.9836808703535811 | global_recall: 0.9783588818755635 | global_auc: 0.9964866896392245| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 134 | global_acc: 98.604% | global_loss: 0.07316475361585617 | global_f1: 0.9810126582278481 | global_precision: 0.9836808703535811 | global_recall: 0.9783588818755635 | global_auc: 0.9964881141467367| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 135 | global_acc: 98.570% | global_loss: 0.0732748731970787 | global_f1: 0.9805165382872677 | global_precision: 0.9854280510018215 | global_recall: 0.975653742110009 | global_auc: 0.9964914379975983| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 136 | global_acc: 98.637% | global_loss: 0.07328782975673676 | global_f1: 0.9814563545906829 | global_precision: 0.984573502722323 | global_recall: 0.9783588818755635 | global_auc: 0.9964885889825741| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 137 | global_acc: 98.637% | global_loss: 0.07329082489013672 | global_f1: 0.9814395654142146 | global_precision: 0.9854545454545455 | global_recall: 0.9774571686203787 | global_auc: 0.9964897760721675| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 138 | global_acc: 98.670% | global_loss: 0.07343026250600815 | global_f1: 0.9819004524886877 | global_precision: 0.9854677565849228 | global_recall: 0.9783588818755635 | global_auc: 0.9964985605351592| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 139 | global_acc: 98.604% | global_loss: 0.07353333383798599 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965099565952561| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 140 | global_acc: 98.604% | global_loss: 0.07378833740949631 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965061579085571| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 141 | global_acc: 98.604% | global_loss: 0.07401659339666367 | global_f1: 0.9810126582278481 | global_precision: 0.9836808703535811 | global_recall: 0.9783588818755635 | global_auc: 0.9965436699397101| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 142 | global_acc: 98.604% | global_loss: 0.0738617479801178 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965374970738241| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 143 | global_acc: 98.604% | global_loss: 0.07399094849824905 | global_f1: 0.9810126582278481 | global_precision: 0.9836808703535811 | global_recall: 0.9783588818755635 | global_auc: 0.9965474686264092| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 144 | global_acc: 98.604% | global_loss: 0.07414136826992035 | global_f1: 0.9810126582278481 | global_precision: 0.9836808703535811 | global_recall: 0.9783588818755635 | global_auc: 0.9965208778195158| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 145 | global_acc: 98.637% | global_loss: 0.07410798966884613 | global_f1: 0.9814395654142146 | global_precision: 0.9854545454545455 | global_recall: 0.9774571686203787 | global_auc: 0.9965142301177925| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 146 | global_acc: 98.570% | global_loss: 0.07422430068254471 | global_f1: 0.9805165382872677 | global_precision: 0.9854280510018215 | global_recall: 0.975653742110009 | global_auc: 0.9965075824160692| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 147 | global_acc: 98.537% | global_loss: 0.07439511269330978 | global_f1: 0.9801084990958407 | global_precision: 0.9827742520398912 | global_recall: 0.9774571686203787 | global_auc: 0.9965555408356447| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 148 | global_acc: 98.570% | global_loss: 0.07448966801166534 | global_f1: 0.9805517865219356 | global_precision: 0.9836660617059891 | global_recall: 0.9774571686203787 | global_auc: 0.9965242016703776| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 149 | global_acc: 98.670% | global_loss: 0.07443130016326904 | global_f1: 0.9819004524886877 | global_precision: 0.9854677565849228 | global_recall: 0.9783588818755635 | global_auc: 0.9965227771628654| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 150 | global_acc: 98.404% | global_loss: 0.07663355767726898 | global_f1: 0.9783783783783783 | global_precision: 0.9774977497749775 | global_recall: 0.9792605951307484 | global_auc: 0.9965410583426044| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 151 | global_acc: 98.670% | global_loss: 0.0750327929854393 | global_f1: 0.9819004524886877 | global_precision: 0.9854677565849228 | global_recall: 0.9783588818755635 | global_auc: 0.9965118559386056| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 152 | global_acc: 98.637% | global_loss: 0.07515319436788559 | global_f1: 0.9814395654142146 | global_precision: 0.9854545454545455 | global_recall: 0.9774571686203787 | global_auc: 0.9965469937905718| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 153 | global_acc: 98.570% | global_loss: 0.07549066841602325 | global_f1: 0.9805693628558518 | global_precision: 0.9827898550724637 | global_recall: 0.9783588818755635 | global_auc: 0.996544619611385| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 154 | global_acc: 98.670% | global_loss: 0.07521477341651917 | global_f1: 0.9819004524886877 | global_precision: 0.9854677565849228 | global_recall: 0.9783588818755635 | global_auc: 0.9965261010137271| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 155 | global_acc: 98.670% | global_loss: 0.0753045454621315 | global_f1: 0.9819004524886877 | global_precision: 0.9854677565849228 | global_recall: 0.9783588818755635 | global_auc: 0.99652372683454| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 156 | global_acc: 98.604% | global_loss: 0.0754164382815361 | global_f1: 0.9809782608695652 | global_precision: 0.9854413102820746 | global_recall: 0.9765554553651938 | global_auc: 0.9965218274911906| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 157 | global_acc: 98.604% | global_loss: 0.07534784823656082 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965669368957417| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 158 | global_acc: 98.604% | global_loss: 0.07562181353569031 | global_f1: 0.9809782608695652 | global_precision: 0.9854413102820746 | global_recall: 0.9765554553651938 | global_auc: 0.9965166042969793| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 159 | global_acc: 98.604% | global_loss: 0.07555364072322845 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965593395223437| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 160 | global_acc: 98.670% | global_loss: 0.0756201520562172 | global_f1: 0.9819004524886877 | global_precision: 0.9854677565849228 | global_recall: 0.9783588818755635 | global_auc: 0.9965363099842307| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 161 | global_acc: 98.637% | global_loss: 0.07583974301815033 | global_f1: 0.9814563545906829 | global_precision: 0.984573502722323 | global_recall: 0.9783588818755635 | global_auc: 0.9965412957605232| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 162 | global_acc: 98.604% | global_loss: 0.07661782205104828 | global_f1: 0.9810298102981029 | global_precision: 0.9828054298642533 | global_recall: 0.9792605951307484 | global_auc: 0.9965731097616276| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 163 | global_acc: 98.637% | global_loss: 0.07606583833694458 | global_f1: 0.9814563545906829 | global_precision: 0.984573502722323 | global_recall: 0.9783588818755635 | global_auc: 0.9965655123882295| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 164 | global_acc: 98.604% | global_loss: 0.07629530131816864 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965750091049772| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 165 | global_acc: 98.670% | global_loss: 0.07626292109489441 | global_f1: 0.9819004524886877 | global_precision: 0.9854677565849228 | global_recall: 0.9783588818755635 | global_auc: 0.9965158920432234| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 166 | global_acc: 98.604% | global_loss: 0.07626703381538391 | global_f1: 0.9810126582278481 | global_precision: 0.9836808703535811 | global_recall: 0.9783588818755635 | global_auc: 0.9965802322991886| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 167 | global_acc: 98.670% | global_loss: 0.07635076344013214 | global_f1: 0.9819004524886877 | global_precision: 0.9854677565849228 | global_recall: 0.9783588818755635 | global_auc: 0.996488588982574| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 168 | global_acc: 98.637% | global_loss: 0.07632371783256531 | global_f1: 0.9814563545906829 | global_precision: 0.984573502722323 | global_recall: 0.9783588818755635 | global_auc: 0.9965640878807176| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 169 | global_acc: 98.604% | global_loss: 0.0765119418501854 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965783329558389| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 170 | global_acc: 98.604% | global_loss: 0.07669579982757568 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965555408356446| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 171 | global_acc: 98.604% | global_loss: 0.07685822993516922 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965526918206203| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 172 | global_acc: 98.604% | global_loss: 0.0768401101231575 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965636130448801| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 173 | global_acc: 98.570% | global_loss: 0.07722152024507523 | global_f1: 0.9805517865219356 | global_precision: 0.9836660617059891 | global_recall: 0.9774571686203787 | global_auc: 0.9965707355824408| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 174 | global_acc: 98.637% | global_loss: 0.07710309326648712 | global_f1: 0.9814563545906829 | global_precision: 0.984573502722323 | global_recall: 0.9783588818755635 | global_auc: 0.9965075824160692| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 175 | global_acc: 98.604% | global_loss: 0.07712287455797195 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.996538446745499| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 176 | global_acc: 98.604% | global_loss: 0.07734540849924088 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965688362390912| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 177 | global_acc: 98.604% | global_loss: 0.07734984904527664 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965650375523921| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 178 | global_acc: 98.604% | global_loss: 0.0775778666138649 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.996510906266931| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 179 | global_acc: 98.604% | global_loss: 0.07752766460180283 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965455692830596| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 180 | global_acc: 98.604% | global_loss: 0.07770659774541855 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965712104182781| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 181 | global_acc: 98.604% | global_loss: 0.07785208523273468 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965498428055961| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 182 | global_acc: 98.637% | global_loss: 0.07802186906337738 | global_f1: 0.9814563545906829 | global_precision: 0.984573502722323 | global_recall: 0.9783588818755635 | global_auc: 0.9965166042969794| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 183 | global_acc: 98.604% | global_loss: 0.07801411300897598 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965536414922951| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 184 | global_acc: 98.604% | global_loss: 0.07822670787572861 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965242016703776| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 185 | global_acc: 98.604% | global_loss: 0.0781128779053688 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965607640298557| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 186 | global_acc: 98.604% | global_loss: 0.07815779745578766 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965607640298557| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 187 | global_acc: 98.604% | global_loss: 0.0782671794295311 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965669368957417| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 188 | global_acc: 98.570% | global_loss: 0.07872797548770905 | global_f1: 0.9805517865219356 | global_precision: 0.9836660617059891 | global_recall: 0.9774571686203787 | global_auc: 0.996573584597465| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 189 | global_acc: 98.570% | global_loss: 0.07865895330905914 | global_f1: 0.9805517865219356 | global_precision: 0.9836660617059891 | global_recall: 0.9774571686203787 | global_auc: 0.9965721600899529| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 190 | global_acc: 98.570% | global_loss: 0.07870230078697205 | global_f1: 0.9805517865219356 | global_precision: 0.9836660617059891 | global_recall: 0.9774571686203787 | global_auc: 0.9965296622825075| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 191 | global_acc: 98.604% | global_loss: 0.07873687893152237 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.996565037552392| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 192 | global_acc: 98.604% | global_loss: 0.07886438816785812 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965678865674166| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 193 | global_acc: 98.570% | global_loss: 0.07915305346250534 | global_f1: 0.9805517865219356 | global_precision: 0.9836660617059891 | global_recall: 0.9774571686203787 | global_auc: 0.9965465189547345| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 194 | global_acc: 98.570% | global_loss: 0.07902196794748306 | global_f1: 0.9805341783612495 | global_precision: 0.9845454545454545 | global_recall: 0.9765554553651938 | global_auc: 0.9965716852541155| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 195 | global_acc: 98.537% | global_loss: 0.07949033379554749 | global_f1: 0.9800724637681161 | global_precision: 0.9845313921747043 | global_recall: 0.975653742110009 | global_auc: 0.9965659872240671| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 196 | global_acc: 98.537% | global_loss: 0.07953115552663803 | global_f1: 0.9800724637681161 | global_precision: 0.9845313921747043 | global_recall: 0.975653742110009 | global_auc: 0.9965659872240671| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 197 | global_acc: 98.570% | global_loss: 0.07941070199012756 | global_f1: 0.9805517865219356 | global_precision: 0.9836660617059891 | global_recall: 0.9774571686203787 | global_auc: 0.9965446196113849| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 198 | global_acc: 98.570% | global_loss: 0.079817995429039 | global_f1: 0.9805517865219356 | global_precision: 0.9836660617059891 | global_recall: 0.9774571686203787 | global_auc: 0.9965517421489456| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 199 | global_acc: 98.604% | global_loss: 0.07968603074550629 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9965348854767186| flobal_FPR: 0.02254283137962128 \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'results\\round-200\\5-clients'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 161\u001b[0m\n\u001b[0;32m    159\u001b[0m all_R \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(all_results, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mglobal_acc\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_f1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_precision\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_recall\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_auc\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_fpr\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    160\u001b[0m flname \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mresults/round-\u001b[39m\u001b[39m{\u001b[39;00mr\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mcl\u001b[39m}\u001b[39;00m\u001b[39m-clients/FedAvg-\u001b[39m\u001b[39m{\u001b[39;00mdataset[d]\u001b[39m}\u001b[39;00m\u001b[39m-results.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 161\u001b[0m all_R\u001b[39m.\u001b[39;49mto_csv(flname, index\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    163\u001b[0m all_avg\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mconcatenate(([dataset[d], r, cl], np\u001b[39m.\u001b[39mmean(all_results, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))))  \u001b[39m# Storing avg values for each dataset\u001b[39;00m\n\u001b[0;32m    164\u001b[0m all_std\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mconcatenate(([dataset[d], r, cl], np\u001b[39m.\u001b[39mstd(all_results, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))))  \u001b[39m# Storing std values for each dataset\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3721\u001b[0m     path_or_buf,\n\u001b[0;32m   3722\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3723\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3724\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3725\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3726\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3727\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3728\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3729\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3730\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3731\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3732\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3733\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3734\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3735\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3736\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3737\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    245\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    246\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:734\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[0;32m    733\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[1;32m--> 734\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[0;32m    736\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[0;32m    737\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    738\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:597\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    595\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[0;32m    596\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'results\\round-200\\5-clients'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def train_model_prox(model, train_loader, loss_fn, optimizer, mu=0.01):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Add the proximal term\n",
    "        for param, param_global in zip(model.parameters(), global_model.parameters()):\n",
    "            loss += (mu / 2) * torch.norm(param - param_global, p=2)**2\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "all_avg = []\n",
    "all_std = []\n",
    "\n",
    "n_clients = [10]\n",
    "n_round = [100]\n",
    "\n",
    "dataset = ['Drebin', 'Malgenome', 'Kronodroid', 'Tuandromd']\n",
    "for d in range(0,1):\n",
    "    if d == 0:\n",
    "        use_data = Drebin_data\n",
    "    elif d == 1:\n",
    "        use_data = Malgenome_data\n",
    "    elif d == 2:\n",
    "        use_data = Kronodroid_data\n",
    "    elif d == 3:\n",
    "        use_data = Tuandromd_data\n",
    "\n",
    "    print('===================================================================================================')\n",
    "    print('Working with:', dataset[d])\n",
    "    print('===================================================================================================')\n",
    "\n",
    "    for r in n_round:  # number of rounds loop\n",
    "        comms_round = r\n",
    "        for cl in n_clients:  # number of clients loop\n",
    "            number_of_clients = cl\n",
    "\n",
    "            print('---------------------------------------------')\n",
    "            print('No. of Clients:', number_of_clients)\n",
    "            print('No. of Rounds:', comms_round)\n",
    "            print('---------------------------------------------')\n",
    "\n",
    "            features = np.array(use_data.iloc[:, range(0, use_data.shape[1] - 1)])  # feature set\n",
    "            labels = use_data.iloc[:, -1]  # labels --> B : Benign and S\n",
    "\n",
    "            # Do feature scaling\n",
    "            X = preprocessing.StandardScaler().fit(features).transform(features)\n",
    "\n",
    "            # binarize the labels\n",
    "            lb = LabelBinarizer()\n",
    "            y = lb.fit_transform(labels)\n",
    "\n",
    "            # split data into training and test set\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                                y, shuffle=True,\n",
    "                                                                test_size=0.2,\n",
    "                                                                random_state=100)\n",
    "\n",
    "            # create clients -- Horizontal FL\n",
    "            clients = create_clients(X_train, y_train, num_clients=number_of_clients, initial='client')\n",
    "\n",
    "            # process and batch the training data for each client\n",
    "            clients_batched = dict()\n",
    "            for (client_name, data) in clients.items():\n",
    "                clients_batched[client_name] = batch_data(data)\n",
    "\n",
    "            # process and batch the test set\n",
    "            test_batched = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
    "                                                                                     torch.tensor(y_test, dtype=torch.float32)),\n",
    "                                                       batch_size=len(y_test), shuffle=False)\n",
    "\n",
    "            # ==============================================\n",
    "            # Traditional FedAvg 2017\n",
    "            # ==============================================\n",
    "            # -----------------------------------------------\n",
    "\n",
    "            all_results = list()\n",
    "\n",
    "            # create optimizer\n",
    "            lr = 0.01\n",
    "            loss = nn.BCELoss()\n",
    "            optimizer = optim.SGD\n",
    "\n",
    "            # initialize global model\n",
    "            smlp_global = SimpleMLP(X.shape[1], 1)\n",
    "            global_model = smlp_global\n",
    "            # -----------------------------------------------\n",
    "\n",
    "            print('|=======================|')\n",
    "            print('|Traditional FedAvg 2017|')\n",
    "            print('|=======================|')\n",
    "\n",
    "            # commence global training loop\n",
    "            for comm_round in range(comms_round):\n",
    "                # get the global model's weights - will serve as the initial weights for all local models\n",
    "                global_weights = [param.data.clone() for param in global_model.parameters()]\n",
    "\n",
    "                # initial list to collect local model weights after scaling\n",
    "                scaled_local_weight_list = list()\n",
    "\n",
    "                # randomize client data - using keys\n",
    "                client_names = list(clients_batched.keys())\n",
    "                random.shuffle(client_names)\n",
    "\n",
    "                # ...\n",
    "\n",
    "                for client in client_names:\n",
    "                    smlp_local = SimpleMLP(X.shape[1], 1)\n",
    "                    local_model = smlp_local\n",
    "                    # set local model weight to the weight of the global model\n",
    "                    local_model.load_state_dict({name: param.clone() for name, param in zip(local_model.state_dict(), global_weights)})\n",
    "                    optimizer = torch.optim.SGD(local_model.parameters(), lr=0.01)\n",
    "\n",
    "                    # fit local model with client's data\n",
    "                    train_loader = DataLoader(TensorDataset(torch.tensor(clients_batched[client].dataset.tensors[0], dtype=torch.float32),\n",
    "                                                            torch.tensor(clients_batched[client].dataset.tensors[1], dtype=torch.float32)),\n",
    "                                              batch_size=32, shuffle=True)\n",
    "\n",
    "                    train_model_prox(local_model, train_loader, loss, optimizer)\n",
    "\n",
    "\n",
    "                    # scale the model weights and add to the list\n",
    "                    scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "                    scaled_weights = scale_model_weights(local_model.state_dict().values(), scaling_factor)\n",
    "                    scaled_local_weight_list.append(scaled_weights)\n",
    "\n",
    "                    # clear session to free memory after each communication round\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                # ...\n",
    "                \n",
    "                # to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "                average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "\n",
    "                # update global model\n",
    "                for param, avg_param in zip(global_model.parameters(), average_weights):\n",
    "                    param.data.copy_(avg_param)\n",
    "\n",
    "                # test global model and print out metrics after each communications round\n",
    "                for X_test_batch, Y_test_batch in test_batched:\n",
    "                    global_acc, global_loss, global_f1, global_precision, global_recall, global_auc, global_fpr = test_model(X_test_batch, Y_test_batch, global_model, comm_round)\n",
    "                    all_results.append([global_acc, global_loss, global_f1, global_precision, global_recall, global_auc, global_fpr])\n",
    "\n",
    "            all_R = pd.DataFrame(all_results, columns=['global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "            flname = f'results/round-{r}/{cl}-clients/FedAvg-{dataset[d]}-results.csv'\n",
    "            all_R.to_csv(flname, index=None)\n",
    "\n",
    "            all_avg.append(np.concatenate(([dataset[d], r, cl], np.mean(all_results, axis=0))))  # Storing avg values for each dataset\n",
    "            all_std.append(np.concatenate(([dataset[d], r, cl], np.std(all_results, axis=0))))  # Storing std values for each dataset\n",
    "\n",
    "ALL_AVG = pd.DataFrame(all_avg, columns=['Dataset', 'num of round', 'num of clients', 'global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_AVG.to_csv('FedAvg-results.csv')\n",
    "\n",
    "ALL_STD = pd.DataFrame(all_std, columns=['Dataset', 'num of round', 'num of clients', 'global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_STD.to_csv('FedAvg-all-std-results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((all_avg[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2893319",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_avg =[]\n",
    "\n",
    "all_std =[]\n",
    "\n",
    "n_clients = [5,10,15]\n",
    "n_round = [10,20]\n",
    "\n",
    "\n",
    "dataset = ['Drebin', 'Malgenome', 'Kronodroid', 'Tuandromd' ]\n",
    "\n",
    "\n",
    "for d in range(0,1):\n",
    "    if d == 0:\n",
    "        use_data = Drebin_data\n",
    "    elif d==1:\n",
    "        use_data = Malgenome_data\n",
    "    elif d==2:\n",
    "        use_data = Kronodroid_data\n",
    "    elif d==3:\n",
    "        use_data = Tuandromd_data\n",
    "        \n",
    "        \n",
    "    print('===================================================================================================')\n",
    "    print('Working with:',dataset[d])\n",
    "    print('===================================================================================================')\n",
    "\n",
    "    for r in n_round: #number of rounds loop\n",
    "        comms_round = r\n",
    "        for cl in n_clients: #number of clients loop\n",
    "            number_of_clients = cl\n",
    "\n",
    "            # from sklearn.utils import shuffle\n",
    "            # use_data = shuffle(use_data)\n",
    "            # use_data\n",
    "            print('---------------------------------------------')\n",
    "            print('No. of Clients:', number_of_clients)\n",
    "            print('No. of Rounds:', comms_round)\n",
    "            print('---------------------------------------------')\n",
    "\n",
    "\n",
    "            features = np.array(use_data.iloc[:,range(0,use_data.shape[1]-1)]) #feature set\n",
    "\n",
    "            labels = use_data.iloc[:,-1] #labels --> B : Benign and S\n",
    "\n",
    "\n",
    "            #Do feature scaling \n",
    "\n",
    "\n",
    "            X = preprocessing.StandardScaler().fit(features).transform(features)\n",
    "\n",
    "\n",
    "            #binarize the labels\n",
    "            lb = LabelBinarizer()\n",
    "            y = lb.fit_transform(labels)\n",
    "\n",
    "\n",
    "            #split data into training and test set\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                                y, shuffle=True,\n",
    "                                                                test_size=0.2, \n",
    "                                                                random_state=100)\n",
    "\n",
    "\n",
    "\n",
    "            #create clients -- Horizontal FL\n",
    "            clients = create_clients(X_train, y_train, num_clients=number_of_clients, initial='client')\n",
    "\n",
    "            #process and batch the training data for each client\n",
    "            clients_batched = dict()\n",
    "            for (client_name, data) in clients.items():\n",
    "                clients_batched[client_name] = batch_data(data)\n",
    "\n",
    "\n",
    "                #process and batch the test set  \n",
    "            test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))\n",
    "\n",
    "            #==============================================\n",
    "            # Traditional FedAvg 2017\n",
    "            #==============================================\n",
    "            #-----------------------------------------------\n",
    "\n",
    "\n",
    "            all_results=list()\n",
    "\n",
    "            #create optimizer\n",
    "            lr = 0.01 \n",
    "            loss='binary_crossentropy'\n",
    "            metrics = ['accuracy']\n",
    "            optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr, \n",
    "                            decay=lr / comms_round, \n",
    "                            momentum=0.9\n",
    "                           )\n",
    "\n",
    "            #initialize global model\n",
    "            smlp_global = SimpleMLP()\n",
    "            global_model = smlp_global.build(X.shape[1],1)\n",
    "            #-----------------------------------------------\n",
    "\n",
    "\n",
    "            print('|=======================|')\n",
    "            print('|Traditional FedAvg 2017|')\n",
    "            print('|=======================|')\n",
    "\n",
    "            #commence global training loop\n",
    "            for comm_round in range(comms_round):\n",
    "\n",
    "                # get the global model's weights - will serve as the initial weights for all local models\n",
    "                global_weights = global_model.get_weights()\n",
    "\n",
    "                #initial list to collect local model weights after scalling\n",
    "                scaled_local_weight_list = list()\n",
    "\n",
    "                #randomize client data - using keys\n",
    "                client_names= list(clients_batched.keys())\n",
    "                random.shuffle(client_names)\n",
    "\n",
    "                #loop through each client and create new local model\n",
    "                for client in client_names:\n",
    "                    smlp_local = SimpleMLP()\n",
    "                    local_model = smlp_local.build(X.shape[1],1)\n",
    "                    local_model.compile(loss=loss, \n",
    "                                  optimizer=optimizer, \n",
    "                                  metrics=metrics)\n",
    "\n",
    "                    #set local model weight to the weight of the global model\n",
    "                    local_model.set_weights(global_weights)\n",
    "\n",
    "                    #fit local model with client's data\n",
    "                    local_model.fit(clients_batched[client], epochs=32, verbose=0)\n",
    "\n",
    "                    #scale the model weights and add to list\n",
    "                    scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "                    scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "                    scaled_local_weight_list.append(scaled_weights)\n",
    "\n",
    "                    #clear session to free memory after each communication round\n",
    "                    keras.backend.clear_session()\n",
    "\n",
    "                #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "                average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "\n",
    "                #update global model \n",
    "                global_model.set_weights(average_weights)\n",
    "\n",
    "                #test global model and print out metrics after each communications round\n",
    "                for(X_test, Y_test) in test_batched:\n",
    "                    global_acc, global_loss, global_f1, global_precision, global_recall, global_auc, global_fpr = test_model(X_test, Y_test, global_model, comm_round)\n",
    "                    all_results.append([global_acc,global_loss.numpy(),global_f1, global_precision, global_recall, global_auc, global_fpr])\n",
    "\n",
    "\n",
    "\n",
    "            all_R = pd.DataFrame(all_results, columns=['global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "            flname = 'results/round-'+str(r)+'/'+str(cl)+'-clients/FedAvg-'+dataset[d]+'-results.csv'\n",
    "            all_R.to_csv(flname, index=None)\n",
    "            \n",
    "            \n",
    "            all_avg.append(np.concatenate(([dataset[d],r,cl],np.mean(all_results,axis=0)))) #Storing avg values for each dataset\n",
    "            all_std.append(np.concatenate(([dataset[d],r,cl],np.std(all_results,axis=0)))) #Storing std values sfor each dataset\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "ALL_AVG = pd.DataFrame(all_avg, columns = ['Dataset', 'num of round', 'num of cliends','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_AVG.to_csv(f'FedAvg-results.csv')     \n",
    "\n",
    "ALL_STD = pd.DataFrame(all_std, columns = ['Dataset', 'num of round', 'num of cliends','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_STD.to_csv('FedAvg-all-std-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6104c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_AVG = pd.DataFrame(all_avg, columns = ['Dataset','Rounds','no-clients','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_AVG.to_csv('FedAvg-all-avg-results.csv')\n",
    "\n",
    "ALL_STD = pd.DataFrame(all_std, columns = ['Dataset','Rounds','no-clients','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_STD.to_csv('FedAvg-all-std-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "# make a little extra space between the subplots\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "s1 = np.array(all_results) #FedAvg\n",
    "\n",
    "t = range(0,s1.shape[0])\n",
    "\n",
    "ax1.plot(t, s1[:,0],label='Acc of FedAvg')\n",
    "ax1.set_xlim(0,s1.shape[0])\n",
    "ax1.set_xlabel('Rounds')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_ylim(0.98,1)\n",
    "ax1.grid(True)\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2.plot(t, s1[:,1],label='Error of FedAvg')\n",
    "ax2.set_xlim(0, s1.shape[0])\n",
    "ax2.set_xlabel('Rounds')\n",
    "ax2.set_ylabel('error')\n",
    "ax2.grid(True)\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3861d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b54df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55b69fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "173907af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from federated_utils_fedavg_copy import *\n",
    "\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4bf76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declear path to your data\n",
    "drebin_data_path = r'data\\drebin.csv'\n",
    "malgenome_data_path = r'data\\malgenome.csv'\n",
    "kronodroid_data_path = r'data\\kronodroid.csv'\n",
    "TUANDROMD_data_path=r'data\\TUANDROMD.csv'\n",
    "\n",
    "\n",
    "\n",
    "Drebin_data = pd.read_csv(drebin_data_path, header = None)\n",
    "\n",
    "Malgenome_data = pd.read_csv(malgenome_data_path)\n",
    "\n",
    "Tuandromd_data=pd.read_csv(TUANDROMD_data_path)\n",
    "\n",
    "kronodroid_data=pd.read_csv(kronodroid_data_path)\n",
    "Kronodroid_data = kronodroid_data.iloc[:,range(1,kronodroid_data.shape[1])]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da6c9299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================\n",
      "Working with: Drebin\n",
      "===================================================================================================\n",
      "---------------------------------------------\n",
      "No. of Clients: 5\n",
      "No. of Rounds: 200\n",
      "---------------------------------------------\n",
      "|=======================|\n",
      "|Traditional FedAvg 2017|\n",
      "|=======================|\n",
      "comm_round: 0 | global_acc: 62.832% | global_loss: 0.6796340346336365 | global_f1: 0.02613240418118467 | global_precision: 0.38461538461538464 | global_recall: 0.013525698827772768 | global_auc: 0.6541146187234418| flobal_FPR: 0.9864743011722272 \n",
      "comm_round: 1 | global_acc: 63.132% | global_loss: 0.6618064641952515 | global_f1: 0.0 | global_precision: 1.0 | global_recall: 0.0 | global_auc: 0.8111566003843321| flobal_FPR: 1.0 \n",
      "comm_round: 2 | global_acc: 63.132% | global_loss: 0.6448431611061096 | global_f1: 0.0 | global_precision: 1.0 | global_recall: 0.0 | global_auc: 0.879148106520873| flobal_FPR: 1.0 \n",
      "comm_round: 3 | global_acc: 63.132% | global_loss: 0.6244479417800903 | global_f1: 0.0 | global_precision: 1.0 | global_recall: 0.0 | global_auc: 0.908679571755055| flobal_FPR: 1.0 \n",
      "comm_round: 4 | global_acc: 63.132% | global_loss: 0.5944366455078125 | global_f1: 0.0 | global_precision: 1.0 | global_recall: 0.0 | global_auc: 0.9294916265074257| flobal_FPR: 1.0 \n",
      "comm_round: 5 | global_acc: 63.132% | global_loss: 0.5488685369491577 | global_f1: 0.0 | global_precision: 1.0 | global_recall: 0.0 | global_auc: 0.948333112534669| flobal_FPR: 1.0 \n",
      "comm_round: 6 | global_acc: 69.515% | global_loss: 0.48485711216926575 | global_f1: 0.29623944742901 | global_precision: 0.9948453608247423 | global_recall: 0.1740306582506763 | global_auc: 0.9651750648507045| flobal_FPR: 0.8259693417493237 \n",
      "comm_round: 7 | global_acc: 89.295% | global_loss: 0.40781357884407043 | global_f1: 0.8308823529411765 | global_precision: 0.9949685534591195 | global_recall: 0.7132551848512173 | global_auc: 0.9763517507909577| flobal_FPR: 0.2867448151487827 \n",
      "comm_round: 8 | global_acc: 93.750% | global_loss: 0.3272477090358734 | global_f1: 0.9097022094140249 | global_precision: 0.9732785200411099 | global_recall: 0.8539224526600541 | global_auc: 0.9816532929153069| flobal_FPR: 0.1460775473399459 \n",
      "comm_round: 9 | global_acc: 94.648% | global_loss: 0.2520699203014374 | global_f1: 0.9245194561650257 | global_precision: 0.962890625 | global_recall: 0.8890892696122633 | global_auc: 0.9846855945728162| flobal_FPR: 0.1109107303877367 \n",
      "comm_round: 10 | global_acc: 94.781% | global_loss: 0.19379134476184845 | global_f1: 0.9270106927010693 | global_precision: 0.9568138195777351 | global_recall: 0.8990081154192967 | global_auc: 0.9872791479165867| flobal_FPR: 0.10099188458070334 \n",
      "comm_round: 11 | global_acc: 95.379% | global_loss: 0.15724395215511322 | global_f1: 0.9362092703074805 | global_precision: 0.9532710280373832 | global_recall: 0.9197475202885482 | global_auc: 0.9887421171315547| flobal_FPR: 0.08025247971145176 \n",
      "comm_round: 12 | global_acc: 95.645% | global_loss: 0.13527610898017883 | global_f1: 0.9402099497946143 | global_precision: 0.9519408502772643 | global_recall: 0.9287646528403968 | global_auc: 0.9898651038869587| flobal_FPR: 0.07123534715960325 \n",
      "comm_round: 13 | global_acc: 95.944% | global_loss: 0.12121672183275223 | global_f1: 0.9442413162705666 | global_precision: 0.9573679332715477 | global_recall: 0.9314697926059513 | global_auc: 0.9907440250219492| flobal_FPR: 0.06853020739404869 \n",
      "comm_round: 14 | global_acc: 96.243% | global_loss: 0.11164502799510956 | global_f1: 0.9484724122207023 | global_precision: 0.959409594095941 | global_recall: 0.9377817853922452 | global_auc: 0.991636716396224| flobal_FPR: 0.062218214607754736 \n",
      "comm_round: 15 | global_acc: 96.410% | global_loss: 0.10431457310914993 | global_f1: 0.9506849315068492 | global_precision: 0.9629972247918593 | global_recall: 0.9386834986474302 | global_auc: 0.9925184865462388| flobal_FPR: 0.061316501352569885 \n",
      "comm_round: 16 | global_acc: 96.543% | global_loss: 0.09888322651386261 | global_f1: 0.9527272727272728 | global_precision: 0.9605866177818515 | global_recall: 0.9449954914337241 | global_auc: 0.9930579000575026| flobal_FPR: 0.05500450856627592 \n",
      "comm_round: 17 | global_acc: 96.742% | global_loss: 0.09387090057134628 | global_f1: 0.9553327256153146 | global_precision: 0.9658986175115207 | global_recall: 0.9449954914337241 | global_auc: 0.9935322610590454| flobal_FPR: 0.05500450856627592 \n",
      "comm_round: 18 | global_acc: 96.809% | global_loss: 0.08989274501800537 | global_f1: 0.9562443026435733 | global_precision: 0.9668202764976959 | global_recall: 0.9458972046889089 | global_auc: 0.9939154535798111| flobal_FPR: 0.05410279531109107 \n",
      "comm_round: 19 | global_acc: 96.809% | global_loss: 0.08642132580280304 | global_f1: 0.9562841530054644 | global_precision: 0.9659613615455381 | global_recall: 0.9467989179440938 | global_auc: 0.9942516373526763| flobal_FPR: 0.05320108205590622 \n",
      "comm_round: 20 | global_acc: 96.975% | global_loss: 0.08392497152090073 | global_f1: 0.9587301587301588 | global_precision: 0.9644160583941606 | global_recall: 0.9531109107303878 | global_auc: 0.9944244775974825| flobal_FPR: 0.046889089269612265 \n",
      "comm_round: 21 | global_acc: 97.108% | global_loss: 0.08187955617904663 | global_f1: 0.9604725124943208 | global_precision: 0.967948717948718 | global_recall: 0.9531109107303878 | global_auc: 0.9945716767070705| flobal_FPR: 0.046889089269612265 \n",
      "comm_round: 22 | global_acc: 97.008% | global_loss: 0.08021502941846848 | global_f1: 0.9592391304347826 | global_precision: 0.9636032757051866 | global_recall: 0.9549143372407575 | global_auc: 0.99470225656235| flobal_FPR: 0.04508566275924256 \n",
      "comm_round: 23 | global_acc: 97.074% | global_loss: 0.07884914427995682 | global_f1: 0.9600725952813066 | global_precision: 0.9662100456621004 | global_recall: 0.9540126239855726 | global_auc: 0.994787252177241| flobal_FPR: 0.045987376014427414 \n",
      "comm_round: 24 | global_acc: 97.207% | global_loss: 0.07749918848276138 | global_f1: 0.9618874773139746 | global_precision: 0.9680365296803652 | global_recall: 0.9558160504959423 | global_auc: 0.9949164075250084| flobal_FPR: 0.04418394950405771 \n",
      "comm_round: 25 | global_acc: 97.207% | global_loss: 0.07629241049289703 | global_f1: 0.9620253164556962 | global_precision: 0.9646418857660924 | global_recall: 0.9594229035166817 | global_auc: 0.9949847838855912| flobal_FPR: 0.0405770964833183 \n",
      "comm_round: 26 | global_acc: 97.307% | global_loss: 0.07555529475212097 | global_f1: 0.9633649932157395 | global_precision: 0.9664246823956443 | global_recall: 0.9603246167718665 | global_auc: 0.9950450880369384| flobal_FPR: 0.03967538322813345 \n",
      "comm_round: 27 | global_acc: 97.274% | global_loss: 0.07451453804969788 | global_f1: 0.9628623188405797 | global_precision: 0.9672429481346679 | global_recall: 0.9585211902614968 | global_auc: 0.9951177379200575| flobal_FPR: 0.04147880973850315 \n",
      "comm_round: 28 | global_acc: 97.241% | global_loss: 0.07374809682369232 | global_f1: 0.9625282167042888 | global_precision: 0.9638336347197106 | global_recall: 0.9612263300270514 | global_auc: 0.9952017838632738| flobal_FPR: 0.0387736699729486 \n",
      "comm_round: 29 | global_acc: 97.374% | global_loss: 0.07458481937646866 | global_f1: 0.9644624381466488 | global_precision: 0.9622980251346499 | global_recall: 0.9666366095581606 | global_auc: 0.9952834556273032| flobal_FPR: 0.033363390441839495 \n",
      "comm_round: 30 | global_acc: 97.340% | global_loss: 0.07258477807044983 | global_f1: 0.963898916967509 | global_precision: 0.964769647696477 | global_recall: 0.9630297565374211 | global_auc: 0.9953133702850582| flobal_FPR: 0.0369702434625789 \n",
      "comm_round: 31 | global_acc: 97.374% | global_loss: 0.07197735458612442 | global_f1: 0.9643662607126747 | global_precision: 0.9648014440433214 | global_recall: 0.9639314697926059 | global_auc: 0.9953883943473644| flobal_FPR: 0.03606853020739405 \n",
      "comm_round: 32 | global_acc: 97.440% | global_loss: 0.07138551771640778 | global_f1: 0.9652370203160272 | global_precision: 0.9665461121157324 | global_recall: 0.9639314697926059 | global_auc: 0.9954463243195245| flobal_FPR: 0.03606853020739405 \n",
      "comm_round: 33 | global_acc: 97.507% | global_loss: 0.0708470568060875 | global_f1: 0.9661093538183462 | global_precision: 0.9682971014492754 | global_recall: 0.9639314697926059 | global_auc: 0.9954439501403378| flobal_FPR: 0.03606853020739405 \n",
      "comm_round: 34 | global_acc: 97.473% | global_loss: 0.0704001858830452 | global_f1: 0.9655797101449276 | global_precision: 0.9699727024567789 | global_recall: 0.9612263300270514 | global_auc: 0.9954790879923038| flobal_FPR: 0.0387736699729486 \n",
      "comm_round: 35 | global_acc: 97.507% | global_loss: 0.0699770450592041 | global_f1: 0.9660786974219809 | global_precision: 0.969147005444646 | global_recall: 0.9630297565374211 | global_auc: 0.9955408166511632| flobal_FPR: 0.0369702434625789 \n",
      "comm_round: 36 | global_acc: 97.606% | global_loss: 0.06973034143447876 | global_f1: 0.9675675675675676 | global_precision: 0.9666966696669667 | global_recall: 0.9684400360685302 | global_auc: 0.9956101426834207| flobal_FPR: 0.031559963931469794 \n",
      "comm_round: 37 | global_acc: 97.507% | global_loss: 0.06929663568735123 | global_f1: 0.9660786974219809 | global_precision: 0.969147005444646 | global_recall: 0.9630297565374211 | global_auc: 0.9956049194892096| flobal_FPR: 0.0369702434625789 \n",
      "comm_round: 38 | global_acc: 97.706% | global_loss: 0.06923548877239227 | global_f1: 0.9688768606224628 | global_precision: 0.9693140794223827 | global_recall: 0.9684400360685302 | global_auc: 0.9956490792220859| flobal_FPR: 0.031559963931469794 \n",
      "comm_round: 39 | global_acc: 97.706% | global_loss: 0.06880486011505127 | global_f1: 0.9688768606224628 | global_precision: 0.9693140794223827 | global_recall: 0.9684400360685302 | global_auc: 0.995666648148069| flobal_FPR: 0.031559963931469794 \n",
      "comm_round: 40 | global_acc: 97.673% | global_loss: 0.06862223893404007 | global_f1: 0.9683830171635049 | global_precision: 0.9701357466063348 | global_recall: 0.9666366095581606 | global_auc: 0.9956908647757754| flobal_FPR: 0.033363390441839495 \n",
      "comm_round: 41 | global_acc: 97.739% | global_loss: 0.06822340190410614 | global_f1: 0.9692585895117541 | global_precision: 0.971894832275612 | global_recall: 0.9666366095581606 | global_auc: 0.9957416722103751| flobal_FPR: 0.033363390441839495 \n",
      "comm_round: 42 | global_acc: 97.806% | global_loss: 0.06893002986907959 | global_f1: 0.9703504043126685 | global_precision: 0.9668755595344674 | global_recall: 0.9738503155996393 | global_auc: 0.9957763352265038| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 43 | global_acc: 97.839% | global_loss: 0.06802547723054886 | global_f1: 0.9706811005863779 | global_precision: 0.9711191335740073 | global_recall: 0.9702434625788999 | global_auc: 0.9957882061224382| flobal_FPR: 0.029756537421100092 \n",
      "comm_round: 44 | global_acc: 97.872% | global_loss: 0.06760796159505844 | global_f1: 0.971093044263776 | global_precision: 0.9728506787330317 | global_recall: 0.9693417493237151 | global_auc: 0.9958447115870865| flobal_FPR: 0.030658250676284943 \n",
      "comm_round: 45 | global_acc: 97.939% | global_loss: 0.06721289455890656 | global_f1: 0.9719710669077758 | global_precision: 0.9746146872166818 | global_recall: 0.9693417493237151 | global_auc: 0.995836639377851| flobal_FPR: 0.030658250676284943 \n",
      "comm_round: 46 | global_acc: 97.939% | global_loss: 0.0685662254691124 | global_f1: 0.9722222222222223 | global_precision: 0.9661620658949243 | global_recall: 0.9783588818755635 | global_auc: 0.9959121382759946| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 47 | global_acc: 98.005% | global_loss: 0.06724590808153152 | global_f1: 0.9729241877256317 | global_precision: 0.973803071364047 | global_recall: 0.9720468890892696 | global_auc: 0.9958997925442226| flobal_FPR: 0.027953110910730387 \n",
      "comm_round: 48 | global_acc: 97.972% | global_loss: 0.06698054820299149 | global_f1: 0.9724604966139955 | global_precision: 0.9737793851717902 | global_recall: 0.9711451758340848 | global_auc: 0.9959254336794411| flobal_FPR: 0.028854824165915238 \n",
      "comm_round: 49 | global_acc: 98.138% | global_loss: 0.06690207123756409 | global_f1: 0.9747520288548241 | global_precision: 0.9747520288548241 | global_recall: 0.9747520288548241 | global_auc: 0.9959705430839922| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 50 | global_acc: 98.072% | global_loss: 0.06700795888900757 | global_f1: 0.9738503155996393 | global_precision: 0.9738503155996393 | global_recall: 0.9738503155996393 | global_auc: 0.9960018822492595| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 51 | global_acc: 98.039% | global_loss: 0.06680521368980408 | global_f1: 0.9734353894642052 | global_precision: 0.9721223021582733 | global_recall: 0.9747520288548241 | global_auc: 0.9959795649649025| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 52 | global_acc: 98.039% | global_loss: 0.06703624129295349 | global_f1: 0.9734353894642052 | global_precision: 0.9721223021582733 | global_recall: 0.9747520288548241 | global_auc: 0.9960090047868202| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 53 | global_acc: 98.072% | global_loss: 0.06671313941478729 | global_f1: 0.9738503155996393 | global_precision: 0.9738503155996393 | global_recall: 0.9738503155996393 | global_auc: 0.9960298975636648| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 54 | global_acc: 98.105% | global_loss: 0.06658891588449478 | global_f1: 0.9742198100407056 | global_precision: 0.9773139745916516 | global_recall: 0.9711451758340848 | global_auc: 0.9960574380422329| flobal_FPR: 0.028854824165915238 \n",
      "comm_round: 55 | global_acc: 98.205% | global_loss: 0.0670899897813797 | global_f1: 0.9756756756756757 | global_precision: 0.9747974797479748 | global_recall: 0.9765554553651938 | global_auc: 0.996076431475728| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 56 | global_acc: 98.105% | global_loss: 0.06657271087169647 | global_f1: 0.9742895805142084 | global_precision: 0.9747292418772563 | global_recall: 0.9738503155996393 | global_auc: 0.9960460419821358| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 57 | global_acc: 98.005% | global_loss: 0.06687947362661362 | global_f1: 0.972875226039783 | global_precision: 0.9755213055303718 | global_recall: 0.9702434625788999 | global_auc: 0.9960308472353395| flobal_FPR: 0.029756537421100092 \n",
      "comm_round: 58 | global_acc: 98.105% | global_loss: 0.06710556894540787 | global_f1: 0.9742895805142084 | global_precision: 0.9747292418772563 | global_recall: 0.9738503155996393 | global_auc: 0.996081179834102| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 59 | global_acc: 98.072% | global_loss: 0.0670095831155777 | global_f1: 0.973826714801444 | global_precision: 0.974706413730804 | global_recall: 0.9729486023444545 | global_auc: 0.9960925758941991| flobal_FPR: 0.027051397655545536 \n",
      "comm_round: 60 | global_acc: 97.972% | global_loss: 0.06680242717266083 | global_f1: 0.9724604966139955 | global_precision: 0.9737793851717902 | global_recall: 0.9711451758340848 | global_auc: 0.9960702586098421| flobal_FPR: 0.028854824165915238 \n",
      "comm_round: 61 | global_acc: 98.039% | global_loss: 0.06678586453199387 | global_f1: 0.9733874605322507 | global_precision: 0.973826714801444 | global_recall: 0.9729486023444545 | global_auc: 0.9960873526999878| flobal_FPR: 0.027051397655545536 \n",
      "comm_round: 62 | global_acc: 98.039% | global_loss: 0.06717789173126221 | global_f1: 0.973339358337099 | global_precision: 0.9755434782608695 | global_recall: 0.9711451758340848 | global_auc: 0.9960797553265898| flobal_FPR: 0.028854824165915238 \n",
      "comm_round: 63 | global_acc: 98.105% | global_loss: 0.06717247515916824 | global_f1: 0.9742895805142084 | global_precision: 0.9747292418772563 | global_recall: 0.9738503155996393 | global_auc: 0.9960940004017111| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 64 | global_acc: 98.138% | global_loss: 0.06753294169902802 | global_f1: 0.9747292418772563 | global_precision: 0.975609756097561 | global_recall: 0.9738503155996393 | global_auc: 0.9960996984317597| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 65 | global_acc: 98.138% | global_loss: 0.06712989509105682 | global_f1: 0.9747292418772563 | global_precision: 0.975609756097561 | global_recall: 0.9738503155996393 | global_auc: 0.9961125189993689| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 66 | global_acc: 98.039% | global_loss: 0.06697344034910202 | global_f1: 0.973339358337099 | global_precision: 0.9755434782608695 | global_recall: 0.9711451758340848 | global_auc: 0.9961243898953035| flobal_FPR: 0.028854824165915238 \n",
      "comm_round: 67 | global_acc: 98.105% | global_loss: 0.06725571304559708 | global_f1: 0.9742663656884876 | global_precision: 0.9755877034358047 | global_recall: 0.9729486023444545 | global_auc: 0.9961248647311408| flobal_FPR: 0.027051397655545536 \n",
      "comm_round: 68 | global_acc: 98.138% | global_loss: 0.06699594110250473 | global_f1: 0.9747064137308039 | global_precision: 0.9764705882352941 | global_recall: 0.9729486023444545 | global_auc: 0.9960949500733859| flobal_FPR: 0.027051397655545536 \n",
      "comm_round: 69 | global_acc: 98.105% | global_loss: 0.06705104559659958 | global_f1: 0.9742198100407056 | global_precision: 0.9773139745916516 | global_recall: 0.9711451758340848 | global_auc: 0.9961039719542962| flobal_FPR: 0.028854824165915238 \n",
      "comm_round: 70 | global_acc: 98.005% | global_loss: 0.07158008217811584 | global_f1: 0.9731903485254692 | global_precision: 0.9645704162976085 | global_recall: 0.981965734896303 | global_auc: 0.9961728231507162| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 71 | global_acc: 98.105% | global_loss: 0.06698684394359589 | global_f1: 0.9742198100407056 | global_precision: 0.9773139745916516 | global_recall: 0.9711451758340848 | global_auc: 0.996107058387239| flobal_FPR: 0.028854824165915238 \n",
      "comm_round: 72 | global_acc: 98.205% | global_loss: 0.06720975786447525 | global_f1: 0.975653742110009 | global_precision: 0.975653742110009 | global_recall: 0.975653742110009 | global_auc: 0.9961395846420996| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 73 | global_acc: 98.138% | global_loss: 0.06728861480951309 | global_f1: 0.9747064137308039 | global_precision: 0.9764705882352941 | global_recall: 0.9729486023444545 | global_auc: 0.996110144820182| flobal_FPR: 0.027051397655545536 \n",
      "comm_round: 74 | global_acc: 98.238% | global_loss: 0.0685337483882904 | global_f1: 0.9761797752808989 | global_precision: 0.9731182795698925 | global_recall: 0.9792605951307484 | global_auc: 0.9961685496281798| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 75 | global_acc: 98.238% | global_loss: 0.06736346334218979 | global_f1: 0.9761153672825597 | global_precision: 0.9756756756756757 | global_recall: 0.9765554553651938 | global_auc: 0.9961386349704249| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 76 | global_acc: 98.138% | global_loss: 0.06862778216600418 | global_f1: 0.974820143884892 | global_precision: 0.9721973094170404 | global_recall: 0.9774571686203787 | global_auc: 0.9961186918652549| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 77 | global_acc: 98.138% | global_loss: 0.06796568632125854 | global_f1: 0.9747292418772563 | global_precision: 0.975609756097561 | global_recall: 0.9738503155996393 | global_auc: 0.9960996984317596| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 78 | global_acc: 98.238% | global_loss: 0.06789403408765793 | global_f1: 0.9760938204781237 | global_precision: 0.9765342960288809 | global_recall: 0.975653742110009 | global_auc: 0.9960992235959223| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 79 | global_acc: 98.271% | global_loss: 0.06802251189947128 | global_f1: 0.9765554553651938 | global_precision: 0.9765554553651938 | global_recall: 0.9765554553651938 | global_auc: 0.9961182170294176| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 80 | global_acc: 98.271% | global_loss: 0.0681416243314743 | global_f1: 0.9765554553651938 | global_precision: 0.9765554553651938 | global_recall: 0.9765554553651938 | global_auc: 0.9960992235959223| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 81 | global_acc: 98.205% | global_loss: 0.06842391192913055 | global_f1: 0.9756975697569756 | global_precision: 0.9739442946990117 | global_recall: 0.9774571686203787 | global_auc: 0.9961305627611894| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 82 | global_acc: 98.205% | global_loss: 0.06901679933071136 | global_f1: 0.9756975697569756 | global_precision: 0.9739442946990117 | global_recall: 0.9774571686203787 | global_auc: 0.9960940004017111| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 83 | global_acc: 98.238% | global_loss: 0.06949926912784576 | global_f1: 0.9761368752814047 | global_precision: 0.9748201438848921 | global_recall: 0.9774571686203787 | global_auc: 0.9961267640744903| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 84 | global_acc: 98.305% | global_loss: 0.06914428621530533 | global_f1: 0.9769959404600811 | global_precision: 0.9774368231046932 | global_recall: 0.9765554553651938 | global_auc: 0.9961044467901334| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 85 | global_acc: 98.271% | global_loss: 0.0693831667304039 | global_f1: 0.9765554553651938 | global_precision: 0.9765554553651938 | global_recall: 0.9765554553651938 | global_auc: 0.9961082454768326| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 86 | global_acc: 98.238% | global_loss: 0.06921243667602539 | global_f1: 0.9760938204781237 | global_precision: 0.9765342960288809 | global_recall: 0.975653742110009 | global_auc: 0.9961125189993689| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 87 | global_acc: 98.238% | global_loss: 0.06908883154392242 | global_f1: 0.9760722347629797 | global_precision: 0.9773960216998192 | global_recall: 0.9747520288548241 | global_auc: 0.9961410091496118| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 88 | global_acc: 98.305% | global_loss: 0.06984279304742813 | global_f1: 0.9770166741775576 | global_precision: 0.9765765765765766 | global_recall: 0.9774571686203787 | global_auc: 0.9961281885820025| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 89 | global_acc: 98.305% | global_loss: 0.06984910368919373 | global_f1: 0.9770166741775576 | global_precision: 0.9765765765765766 | global_recall: 0.9774571686203787 | global_auc: 0.9960954249092233| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 90 | global_acc: 98.205% | global_loss: 0.0706576481461525 | global_f1: 0.9756975697569756 | global_precision: 0.9739442946990117 | global_recall: 0.9774571686203787 | global_auc: 0.996098748760085| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 91 | global_acc: 98.271% | global_loss: 0.07149935513734818 | global_f1: 0.9766187050359711 | global_precision: 0.9739910313901345 | global_recall: 0.9792605951307484 | global_auc: 0.9960930507300364| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 92 | global_acc: 98.338% | global_loss: 0.07084252685308456 | global_f1: 0.9774571686203787 | global_precision: 0.9774571686203787 | global_recall: 0.9774571686203787 | global_auc: 0.9960821295057767| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 93 | global_acc: 98.338% | global_loss: 0.0707579031586647 | global_f1: 0.9774571686203787 | global_precision: 0.9774571686203787 | global_recall: 0.9774571686203787 | global_auc: 0.9960837914312075| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 94 | global_acc: 98.338% | global_loss: 0.0702332928776741 | global_f1: 0.9774368231046933 | global_precision: 0.978319783197832 | global_recall: 0.9765554553651938 | global_auc: 0.9961025474467838| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 95 | global_acc: 98.305% | global_loss: 0.07035960257053375 | global_f1: 0.9769335142469472 | global_precision: 0.9800362976406534 | global_recall: 0.9738503155996393 | global_auc: 0.9960854533566383| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 96 | global_acc: 98.271% | global_loss: 0.07135045528411865 | global_f1: 0.9765765765765766 | global_precision: 0.9756975697569757 | global_recall: 0.9774571686203787 | global_auc: 0.9961082454768325| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 97 | global_acc: 98.338% | global_loss: 0.0709606260061264 | global_f1: 0.9774571686203787 | global_precision: 0.9774571686203787 | global_recall: 0.9774571686203787 | global_auc: 0.9960792804907523| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 98 | global_acc: 98.305% | global_loss: 0.07213259488344193 | global_f1: 0.9770373705538046 | global_precision: 0.9757194244604317 | global_recall: 0.9783588818755635 | global_auc: 0.9960890146254188| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 99 | global_acc: 98.305% | global_loss: 0.07142366468906403 | global_f1: 0.9770166741775576 | global_precision: 0.9765765765765766 | global_recall: 0.9774571686203787 | global_auc: 0.9960759566398907| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 100 | global_acc: 98.305% | global_loss: 0.07265517115592957 | global_f1: 0.9770373705538046 | global_precision: 0.9757194244604317 | global_recall: 0.9783588818755635 | global_auc: 0.996055063863046| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 101 | global_acc: 98.305% | global_loss: 0.07271133363246918 | global_f1: 0.9770166741775576 | global_precision: 0.9765765765765766 | global_recall: 0.9774571686203787 | global_auc: 0.9960303723995021| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 102 | global_acc: 98.338% | global_loss: 0.07255756855010986 | global_f1: 0.9774368231046933 | global_precision: 0.978319783197832 | global_recall: 0.9765554553651938 | global_auc: 0.9960327465786892| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 103 | global_acc: 98.338% | global_loss: 0.07308339327573776 | global_f1: 0.9774571686203787 | global_precision: 0.9774571686203787 | global_recall: 0.9774571686203787 | global_auc: 0.9959866875024631| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 104 | global_acc: 98.238% | global_loss: 0.07364606857299805 | global_f1: 0.9759855006796557 | global_precision: 0.9808743169398907 | global_recall: 0.9711451758340848 | global_auc: 0.9959964216371296| flobal_FPR: 0.028854824165915238 \n",
      "comm_round: 105 | global_acc: 98.305% | global_loss: 0.0734541267156601 | global_f1: 0.9770373705538046 | global_precision: 0.9757194244604317 | global_recall: 0.9783588818755635 | global_auc: 0.9959909610249996| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 106 | global_acc: 98.371% | global_loss: 0.07289566099643707 | global_f1: 0.9778581111613194 | global_precision: 0.980072463768116 | global_recall: 0.975653742110009 | global_auc: 0.9960498406688347| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 107 | global_acc: 98.371% | global_loss: 0.07319936901330948 | global_f1: 0.9778781038374718 | global_precision: 0.9792043399638336 | global_recall: 0.9765554553651938 | global_auc: 0.9960562509526394| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 108 | global_acc: 98.305% | global_loss: 0.07405190914869308 | global_f1: 0.9769335142469472 | global_precision: 0.9800362976406534 | global_recall: 0.9738503155996393 | global_auc: 0.9960118538018443| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 109 | global_acc: 98.404% | global_loss: 0.07365527749061584 | global_f1: 0.9783393501805054 | global_precision: 0.979223125564589 | global_recall: 0.9774571686203787 | global_auc: 0.9960572006243142| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 110 | global_acc: 98.271% | global_loss: 0.07738109678030014 | global_f1: 0.9766606822262118 | global_precision: 0.9722966934763181 | global_recall: 0.9810640216411182 | global_auc: 0.9958724894835733| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 111 | global_acc: 98.338% | global_loss: 0.07400993257761002 | global_f1: 0.9774571686203787 | global_precision: 0.9774571686203787 | global_recall: 0.9774571686203787 | global_auc: 0.9960123286376816| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 112 | global_acc: 98.404% | global_loss: 0.07407131791114807 | global_f1: 0.978319783197832 | global_precision: 0.9800904977375565 | global_recall: 0.9765554553651938 | global_auc: 0.9959985583983978| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 113 | global_acc: 98.338% | global_loss: 0.07492928951978683 | global_f1: 0.9774571686203787 | global_precision: 0.9774571686203787 | global_recall: 0.9774571686203787 | global_auc: 0.9959752914423661| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 114 | global_acc: 98.371% | global_loss: 0.07537389546632767 | global_f1: 0.9778980604420388 | global_precision: 0.9783393501805054 | global_recall: 0.9774571686203787 | global_auc: 0.9959510748146596| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 115 | global_acc: 98.438% | global_loss: 0.07492520660161972 | global_f1: 0.9788001804239964 | global_precision: 0.9792418772563177 | global_recall: 0.9783588818755635 | global_auc: 0.995971492755667| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 116 | global_acc: 98.404% | global_loss: 0.0772225484251976 | global_f1: 0.9782411604714416 | global_precision: 0.98359161349134 | global_recall: 0.9729486023444545 | global_auc: 0.9959358800678636| flobal_FPR: 0.027051397655545536 \n",
      "comm_round: 117 | global_acc: 98.438% | global_loss: 0.07515677809715271 | global_f1: 0.9787810383747179 | global_precision: 0.9801084990958409 | global_recall: 0.9774571686203787 | global_auc: 0.9959629457105943| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 118 | global_acc: 98.438% | global_loss: 0.07554831355810165 | global_f1: 0.9787618617261635 | global_precision: 0.9809782608695652 | global_recall: 0.9765554553651938 | global_auc: 0.9959558231730334| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 119 | global_acc: 98.471% | global_loss: 0.07560088485479355 | global_f1: 0.9792418772563176 | global_precision: 0.980126467931346 | global_recall: 0.9783588818755635 | global_auc: 0.9959805146365772| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 120 | global_acc: 98.404% | global_loss: 0.07604868710041046 | global_f1: 0.9783001808318263 | global_precision: 0.9809610154125114 | global_recall: 0.975653742110009 | global_auc: 0.9959543986655215| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 121 | global_acc: 98.404% | global_loss: 0.07661260664463043 | global_f1: 0.9783001808318263 | global_precision: 0.9809610154125114 | global_recall: 0.975653742110009 | global_auc: 0.9959465638742047| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 122 | global_acc: 98.471% | global_loss: 0.07672812044620514 | global_f1: 0.9792605951307484 | global_precision: 0.9792605951307484 | global_recall: 0.9792605951307484 | global_auc: 0.9959095266788889| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 123 | global_acc: 98.471% | global_loss: 0.07690933346748352 | global_f1: 0.9792792792792793 | global_precision: 0.9783978397839784 | global_recall: 0.9801623083859333 | global_auc: 0.9959083395892955| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 124 | global_acc: 98.471% | global_loss: 0.07695861905813217 | global_f1: 0.9792231255645889 | global_precision: 0.9809954751131221 | global_recall: 0.9774571686203787 | global_auc: 0.9959619960389194| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 125 | global_acc: 98.537% | global_loss: 0.0767950713634491 | global_f1: 0.9801444043321298 | global_precision: 0.981029810298103 | global_recall: 0.9792605951307484 | global_auc: 0.9959515496504969| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 126 | global_acc: 98.404% | global_loss: 0.07825664430856705 | global_f1: 0.9782608695652174 | global_precision: 0.9827115559599636 | global_recall: 0.9738503155996393 | global_auc: 0.995901691887572| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 127 | global_acc: 98.471% | global_loss: 0.07731961458921432 | global_f1: 0.9792605951307484 | global_precision: 0.9792605951307484 | global_recall: 0.9792605951307484 | global_auc: 0.9959259085152785| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 128 | global_acc: 98.471% | global_loss: 0.0783434733748436 | global_f1: 0.9792979297929794 | global_precision: 0.977538185085355 | global_recall: 0.9810640216411182 | global_auc: 0.9958318910194772| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 129 | global_acc: 98.404% | global_loss: 0.07807203382253647 | global_f1: 0.9783783783783783 | global_precision: 0.9774977497749775 | global_recall: 0.9792605951307484 | global_auc: 0.9958684533789557| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 130 | global_acc: 98.471% | global_loss: 0.07799138873815536 | global_f1: 0.9792605951307484 | global_precision: 0.9792605951307484 | global_recall: 0.9792605951307484 | global_auc: 0.9959268581869534| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 131 | global_acc: 98.404% | global_loss: 0.0787450522184372 | global_f1: 0.9783783783783783 | global_precision: 0.9774977497749775 | global_recall: 0.9792605951307484 | global_auc: 0.995844474169168| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 132 | global_acc: 98.438% | global_loss: 0.07843221724033356 | global_f1: 0.9788192879675529 | global_precision: 0.9783783783783784 | global_recall: 0.9792605951307484 | global_auc: 0.9958812739465648| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 133 | global_acc: 98.504% | global_loss: 0.07857123762369156 | global_f1: 0.979702300405954 | global_precision: 0.98014440433213 | global_recall: 0.9792605951307484 | global_auc: 0.995910238932645| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 134 | global_acc: 98.438% | global_loss: 0.07873353362083435 | global_f1: 0.9788192879675529 | global_precision: 0.9783783783783784 | global_recall: 0.9792605951307484 | global_auc: 0.9958250058998354| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 135 | global_acc: 98.471% | global_loss: 0.07899399846792221 | global_f1: 0.9792792792792793 | global_precision: 0.9783978397839784 | global_recall: 0.9801623083859333 | global_auc: 0.9958411503183061| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 136 | global_acc: 98.471% | global_loss: 0.07908260077238083 | global_f1: 0.9792605951307484 | global_precision: 0.9792605951307484 | global_recall: 0.9792605951307484 | global_auc: 0.9958639424385004| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 137 | global_acc: 98.537% | global_loss: 0.07971189171075821 | global_f1: 0.9801264679313461 | global_precision: 0.9819004524886877 | global_recall: 0.9783588818755635 | global_auc: 0.995872726901492| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 138 | global_acc: 98.438% | global_loss: 0.08054951578378677 | global_f1: 0.9787618617261635 | global_precision: 0.9809782608695652 | global_recall: 0.9765554553651938 | global_auc: 0.9958530212142407| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 139 | global_acc: 98.438% | global_loss: 0.08018586039543152 | global_f1: 0.9788192879675529 | global_precision: 0.9783783783783784 | global_recall: 0.9792605951307484 | global_auc: 0.9958233439744044| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 140 | global_acc: 98.371% | global_loss: 0.08212712407112122 | global_f1: 0.9779775280898877 | global_precision: 0.974910394265233 | global_recall: 0.9810640216411182 | global_auc: 0.9958036382871532| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 141 | global_acc: 98.504% | global_loss: 0.08005527406930923 | global_f1: 0.979702300405954 | global_precision: 0.98014440433213 | global_recall: 0.9792605951307484 | global_auc: 0.9958556328113463| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 142 | global_acc: 98.404% | global_loss: 0.08229561895132065 | global_f1: 0.9784172661870504 | global_precision: 0.9757847533632287 | global_recall: 0.9810640216411182 | global_auc: 0.9957993647646167| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 143 | global_acc: 98.438% | global_loss: 0.0812143087387085 | global_f1: 0.9788192879675529 | global_precision: 0.9783783783783784 | global_recall: 0.9792605951307484 | global_auc: 0.9958169336905999| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 144 | global_acc: 98.570% | global_loss: 0.08151957392692566 | global_f1: 0.9805693628558518 | global_precision: 0.9827898550724637 | global_recall: 0.9783588818755635 | global_auc: 0.995858956662208| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 145 | global_acc: 98.438% | global_loss: 0.08173563331365585 | global_f1: 0.9788192879675529 | global_precision: 0.9783783783783784 | global_recall: 0.9792605951307484 | global_auc: 0.9957912925553813| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 146 | global_acc: 98.404% | global_loss: 0.08331292867660522 | global_f1: 0.9784172661870504 | global_precision: 0.9757847533632287 | global_recall: 0.9810640216411182 | global_auc: 0.9957758603906665| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 147 | global_acc: 98.471% | global_loss: 0.08176427334547043 | global_f1: 0.9792605951307484 | global_precision: 0.9792605951307484 | global_recall: 0.9792605951307484 | global_auc: 0.9958385387212007| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 148 | global_acc: 98.537% | global_loss: 0.08228567242622375 | global_f1: 0.9801444043321298 | global_precision: 0.981029810298103 | global_recall: 0.9792605951307484 | global_auc: 0.9958326032732334| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 149 | global_acc: 98.172% | global_loss: 0.08659368008375168 | global_f1: 0.9753473778574631 | global_precision: 0.9696969696969697 | global_recall: 0.9810640216411182 | global_auc: 0.9957806087490403| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 150 | global_acc: 98.537% | global_loss: 0.08235131204128265 | global_f1: 0.9801444043321298 | global_precision: 0.981029810298103 | global_recall: 0.9792605951307484 | global_auc: 0.9958226317206484| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 151 | global_acc: 98.404% | global_loss: 0.08347915858030319 | global_f1: 0.9783978397839784 | global_precision: 0.9766397124887691 | global_recall: 0.9801623083859333 | global_auc: 0.9957656514201627| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 152 | global_acc: 98.205% | global_loss: 0.090916708111763 | global_f1: 0.9758281110116384 | global_precision: 0.9688888888888889 | global_recall: 0.9828674481514879 | global_auc: 0.9957772848981785| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 153 | global_acc: 98.438% | global_loss: 0.0830143392086029 | global_f1: 0.9788192879675529 | global_precision: 0.9783783783783784 | global_recall: 0.9792605951307484 | global_auc: 0.9958100485709578| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 154 | global_acc: 98.404% | global_loss: 0.08361721783876419 | global_f1: 0.9783783783783783 | global_precision: 0.9774977497749775 | global_recall: 0.9792605951307484 | global_auc: 0.9958342651986641| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 155 | global_acc: 98.604% | global_loss: 0.08424173295497894 | global_f1: 0.9810126582278481 | global_precision: 0.9836808703535811 | global_recall: 0.9783588818755635 | global_auc: 0.9958413877362249| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 156 | global_acc: 98.338% | global_loss: 0.08628753572702408 | global_f1: 0.977538185085355 | global_precision: 0.9740376007162042 | global_recall: 0.9810640216411182 | global_auc: 0.995835927124095| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 157 | global_acc: 98.238% | global_loss: 0.08873453736305237 | global_f1: 0.9762438368444645 | global_precision: 0.9705882352941176 | global_recall: 0.981965734896303 | global_auc: 0.9958200201235428| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 158 | global_acc: 98.570% | global_loss: 0.0844564437866211 | global_f1: 0.98058690744921 | global_precision: 0.9819168173598554 | global_recall: 0.9792605951307484 | global_auc: 0.9958411503183061| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 159 | global_acc: 98.504% | global_loss: 0.08486990630626678 | global_f1: 0.9797205948625507 | global_precision: 0.9792792792792793 | global_recall: 0.9801623083859333 | global_auc: 0.9957870190328449| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 160 | global_acc: 98.604% | global_loss: 0.08571669459342957 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9957613778976264| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 161 | global_acc: 98.471% | global_loss: 0.08525697141885757 | global_f1: 0.9792418772563176 | global_precision: 0.980126467931346 | global_recall: 0.9783588818755635 | global_auc: 0.9957739610473169| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 162 | global_acc: 98.604% | global_loss: 0.08584709465503693 | global_f1: 0.9810126582278481 | global_precision: 0.9836808703535811 | global_recall: 0.9783588818755635 | global_auc: 0.9957808461669588| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 163 | global_acc: 98.537% | global_loss: 0.0857471227645874 | global_f1: 0.9801084990958407 | global_precision: 0.9827742520398912 | global_recall: 0.9774571686203787 | global_auc: 0.9957770474802599| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 164 | global_acc: 98.471% | global_loss: 0.08624374121427536 | global_f1: 0.9792792792792793 | global_precision: 0.9783978397839784 | global_recall: 0.9801623083859333 | global_auc: 0.995775385554829| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 165 | global_acc: 98.570% | global_loss: 0.08581747859716415 | global_f1: 0.9805693628558518 | global_precision: 0.9827898550724637 | global_recall: 0.9783588818755635 | global_auc: 0.9957730113756422| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 166 | global_acc: 98.537% | global_loss: 0.08605708181858063 | global_f1: 0.9801084990958407 | global_precision: 0.9827742520398912 | global_recall: 0.9774571686203787 | global_auc: 0.9957806087490402| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 167 | global_acc: 98.604% | global_loss: 0.08708292245864868 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9958193078697868| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 168 | global_acc: 98.504% | global_loss: 0.08645335584878922 | global_f1: 0.9797205948625507 | global_precision: 0.9792792792792793 | global_recall: 0.9801623083859333 | global_auc: 0.9957649391664066| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 169 | global_acc: 98.504% | global_loss: 0.08731108158826828 | global_f1: 0.9797205948625507 | global_precision: 0.9792792792792793 | global_recall: 0.9801623083859333 | global_auc: 0.9957556798675777| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 170 | global_acc: 98.537% | global_loss: 0.08753341436386108 | global_f1: 0.9801623083859333 | global_precision: 0.9801623083859333 | global_recall: 0.9801623083859333 | global_auc: 0.9957535431063095| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 171 | global_acc: 98.504% | global_loss: 0.08777432888746262 | global_f1: 0.9797205948625507 | global_precision: 0.9792792792792793 | global_recall: 0.9801623083859333 | global_auc: 0.9957609030617889| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 172 | global_acc: 98.537% | global_loss: 0.08878255635499954 | global_f1: 0.9800543970988214 | global_precision: 0.9854147675478578 | global_recall: 0.9747520288548241 | global_auc: 0.9958276174969409| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 173 | global_acc: 98.371% | global_loss: 0.09063203632831573 | global_f1: 0.9779775280898877 | global_precision: 0.974910394265233 | global_recall: 0.9810640216411182 | global_auc: 0.9957808461669589| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 174 | global_acc: 98.570% | global_loss: 0.08810045570135117 | global_f1: 0.9805693628558518 | global_precision: 0.9827898550724637 | global_recall: 0.9783588818755635 | global_auc: 0.9957756229727478| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 175 | global_acc: 98.537% | global_loss: 0.08814989030361176 | global_f1: 0.9801264679313461 | global_precision: 0.9819004524886877 | global_recall: 0.9783588818755635 | global_auc: 0.9957618527334636| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 176 | global_acc: 98.537% | global_loss: 0.08861600607633591 | global_f1: 0.9801444043321298 | global_precision: 0.981029810298103 | global_recall: 0.9792605951307484 | global_auc: 0.9957483199120983| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 177 | global_acc: 98.570% | global_loss: 0.08862422406673431 | global_f1: 0.9805693628558518 | global_precision: 0.9827898550724637 | global_recall: 0.9783588818755635 | global_auc: 0.9957972280033485| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 178 | global_acc: 98.404% | global_loss: 0.09155677258968353 | global_f1: 0.9784172661870504 | global_precision: 0.9757847533632287 | global_recall: 0.9810640216411182 | global_auc: 0.995795328659999| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 179 | global_acc: 98.537% | global_loss: 0.08930248767137527 | global_f1: 0.9801264679313461 | global_precision: 0.9819004524886877 | global_recall: 0.9783588818755635 | global_auc: 0.9957252903739855| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 180 | global_acc: 98.570% | global_loss: 0.08953963220119476 | global_f1: 0.9805693628558518 | global_precision: 0.9827898550724637 | global_recall: 0.9783588818755635 | global_auc: 0.9957920048091373| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 181 | global_acc: 98.570% | global_loss: 0.08957908302545547 | global_f1: 0.9805693628558518 | global_precision: 0.9827898550724637 | global_recall: 0.9783588818755635 | global_auc: 0.9957381109415947| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 182 | global_acc: 98.537% | global_loss: 0.09008775651454926 | global_f1: 0.9801444043321298 | global_precision: 0.981029810298103 | global_recall: 0.9792605951307484 | global_auc: 0.995736449016164| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 183 | global_acc: 98.570% | global_loss: 0.09032818675041199 | global_f1: 0.9805517865219356 | global_precision: 0.9836660617059891 | global_recall: 0.9774571686203787 | global_auc: 0.9957385857774321| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 184 | global_acc: 98.537% | global_loss: 0.0905139222741127 | global_f1: 0.9801084990958407 | global_precision: 0.9827742520398912 | global_recall: 0.9774571686203787 | global_auc: 0.9958069621380148| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 185 | global_acc: 98.604% | global_loss: 0.09086905419826508 | global_f1: 0.9810298102981029 | global_precision: 0.9828054298642533 | global_recall: 0.9792605951307484 | global_auc: 0.9957364490161639| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 186 | global_acc: 98.537% | global_loss: 0.0910051241517067 | global_f1: 0.9801444043321298 | global_precision: 0.981029810298103 | global_recall: 0.9792605951307484 | global_auc: 0.9957732487935609| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 187 | global_acc: 98.537% | global_loss: 0.09131397306919098 | global_f1: 0.9801084990958407 | global_precision: 0.9827742520398912 | global_recall: 0.9774571686203787 | global_auc: 0.9957763352265037| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 188 | global_acc: 98.570% | global_loss: 0.09099428355693817 | global_f1: 0.9805693628558518 | global_precision: 0.9827898550724637 | global_recall: 0.9783588818755635 | global_auc: 0.9957903428837066| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 189 | global_acc: 98.570% | global_loss: 0.09135972708463669 | global_f1: 0.9805693628558518 | global_precision: 0.9827898550724637 | global_recall: 0.9783588818755635 | global_auc: 0.9957927170628935| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 190 | global_acc: 98.570% | global_loss: 0.09144420921802521 | global_f1: 0.98058690744921 | global_precision: 0.9819168173598554 | global_recall: 0.9792605951307484 | global_auc: 0.9957927170628935| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 191 | global_acc: 98.570% | global_loss: 0.09154655784368515 | global_f1: 0.98058690744921 | global_precision: 0.9819168173598554 | global_recall: 0.9792605951307484 | global_auc: 0.9957920048091373| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 192 | global_acc: 98.570% | global_loss: 0.09195580333471298 | global_f1: 0.98058690744921 | global_precision: 0.9819168173598554 | global_recall: 0.9792605951307484 | global_auc: 0.9958131350039008| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 193 | global_acc: 98.570% | global_loss: 0.09229578822851181 | global_f1: 0.98058690744921 | global_precision: 0.9819168173598554 | global_recall: 0.9792605951307484 | global_auc: 0.9958088614813644| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 194 | global_acc: 98.504% | global_loss: 0.09245897829532623 | global_f1: 0.9796472184531885 | global_precision: 0.9827586206896551 | global_recall: 0.9765554553651938 | global_auc: 0.9957927170628935| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 195 | global_acc: 98.570% | global_loss: 0.09237102419137955 | global_f1: 0.98058690744921 | global_precision: 0.9819168173598554 | global_recall: 0.9792605951307484 | global_auc: 0.9958418625720623| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 196 | global_acc: 98.570% | global_loss: 0.0925326719880104 | global_f1: 0.98058690744921 | global_precision: 0.9819168173598554 | global_recall: 0.9792605951307484 | global_auc: 0.9958504096171351| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 197 | global_acc: 98.504% | global_loss: 0.09284544736146927 | global_f1: 0.9796656122910077 | global_precision: 0.9818840579710145 | global_recall: 0.9774571686203787 | global_auc: 0.995809098899283| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 198 | global_acc: 98.504% | global_loss: 0.09312710165977478 | global_f1: 0.9796839729119639 | global_precision: 0.9810126582278481 | global_recall: 0.9783588818755635 | global_auc: 0.9958202575414614| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 199 | global_acc: 98.504% | global_loss: 0.09322299063205719 | global_f1: 0.9796839729119639 | global_precision: 0.9810126582278481 | global_recall: 0.9783588818755635 | global_auc: 0.9958212072131362| flobal_FPR: 0.02164111812443643 \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'results\\round-200\\5-clients'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 172\u001b[0m\n\u001b[0;32m    170\u001b[0m all_R \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(all_results, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mglobal_acc\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_f1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_precision\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_recall\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_auc\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_fpr\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    171\u001b[0m flname \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mresults/round-\u001b[39m\u001b[39m{\u001b[39;00mr\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mcl\u001b[39m}\u001b[39;00m\u001b[39m-clients/FedAvg-\u001b[39m\u001b[39m{\u001b[39;00mdataset[d]\u001b[39m}\u001b[39;00m\u001b[39m-results.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 172\u001b[0m all_R\u001b[39m.\u001b[39;49mto_csv(flname, index\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    174\u001b[0m all_avg\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mconcatenate(([dataset[d], r, cl], np\u001b[39m.\u001b[39mmean(all_results, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))))  \u001b[39m# Storing avg values for each dataset\u001b[39;00m\n\u001b[0;32m    175\u001b[0m all_std\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mconcatenate(([dataset[d], r, cl], np\u001b[39m.\u001b[39mstd(all_results, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))))  \u001b[39m# Storing std values for each dataset\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3721\u001b[0m     path_or_buf,\n\u001b[0;32m   3722\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3723\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3724\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3725\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3726\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3727\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3728\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3729\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3730\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3731\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3732\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3733\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3734\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3735\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3736\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3737\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    245\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    246\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:734\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[0;32m    733\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[1;32m--> 734\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[0;32m    736\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[0;32m    737\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    738\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:597\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    595\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[0;32m    596\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'results\\round-200\\5-clients'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def train_model(model, train_loader, loss_fn, optimizer,eps):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Randomly choose whether to use original or adversarial examples\n",
    "        use_original = torch.rand(1).item() > 0.5\n",
    "        if use_original:\n",
    "            # Forward pass (original examples)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "        else:\n",
    "            # Generate adversarial examples\n",
    "            adv_inputs = inputs + eps * torch.randn_like(inputs)\n",
    "            adv_inputs = torch.clamp(adv_inputs, min=-1.0, max=1.0)  # Clip to a valid range\n",
    "            # Forward pass on adversarial examples and compute the loss\n",
    "            adv_outputs = model(adv_inputs)\n",
    "            adv_loss = loss_fn(adv_outputs, labels)\n",
    "            adv_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "all_avg = []\n",
    "all_std = []\n",
    "\n",
    "n_clients = [10]\n",
    "n_round = [100]\n",
    "\n",
    "dataset = ['Drebin', 'Malgenome', 'Kronodroid', 'Tuandromd']\n",
    "\n",
    "# for d in range(0,1):\n",
    "for d in range(0, 2):\n",
    "    if d == 0:\n",
    "        use_data = Drebin_data\n",
    "    elif d == 1:\n",
    "        use_data = Malgenome_data\n",
    "    elif d == 2:\n",
    "        use_data = Kronodroid_data\n",
    "    elif d == 3:\n",
    "        use_data = Tuandromd_data\n",
    "\n",
    "    print('===================================================================================================')\n",
    "    print('Working with:', dataset[d])\n",
    "    print('===================================================================================================')\n",
    "\n",
    "    for r in n_round:  # number of rounds loop\n",
    "        comms_round = r\n",
    "        for cl in n_clients:  # number of clients loop\n",
    "            number_of_clients = cl\n",
    "\n",
    "            print('---------------------------------------------')\n",
    "            print('No. of Clients:', number_of_clients)\n",
    "            print('No. of Rounds:', comms_round)\n",
    "            print('---------------------------------------------')\n",
    "\n",
    "            features = np.array(use_data.iloc[:, range(0, use_data.shape[1] - 1)])  # feature set\n",
    "            labels = use_data.iloc[:, -1]  # labels --> B : Benign and S\n",
    "\n",
    "            # Do feature scaling\n",
    "            X = preprocessing.StandardScaler().fit(features).transform(features)\n",
    "\n",
    "            # binarize the labels\n",
    "            lb = LabelBinarizer()\n",
    "            y = lb.fit_transform(labels)\n",
    "\n",
    "            # split data into training and test set\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                                y, shuffle=True,\n",
    "                                                                test_size=0.2,\n",
    "                                                                random_state=100)\n",
    "\n",
    "            # create clients -- Horizontal FL\n",
    "            clients = create_clients(X_train, y_train, num_clients=number_of_clients, initial='client')\n",
    "\n",
    "            # process and batch the training data for each client\n",
    "            clients_batched = dict()\n",
    "            for (client_name, data) in clients.items():\n",
    "                clients_batched[client_name] = batch_data(data)\n",
    "\n",
    "            # process and batch the test set\n",
    "            test_batched = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
    "                                                                                     torch.tensor(y_test, dtype=torch.float32)),\n",
    "                                                       batch_size=len(y_test), shuffle=False)\n",
    "\n",
    "            # ==============================================\n",
    "            # Traditional FedAvg 2017\n",
    "            # ==============================================\n",
    "            # -----------------------------------------------\n",
    "\n",
    "            all_results = list()\n",
    "\n",
    "            # create optimizer\n",
    "            lr = 0.01\n",
    "            loss = nn.BCELoss()\n",
    "            optimizer = optim.SGD\n",
    "\n",
    "            # initialize global model\n",
    "            smlp_global = SimpleMLP(X.shape[1], 1)\n",
    "            global_model = smlp_global\n",
    "            # -----------------------------------------------\n",
    "\n",
    "            print('|=======================|')\n",
    "            print('|Traditional FedAvg 2017|')\n",
    "            print('|=======================|')\n",
    "\n",
    "            # commence global training loop\n",
    "            for comm_round in range(comms_round):\n",
    "                # get the global model's weights - will serve as the initial weights for all local models\n",
    "                global_weights = [param.data.clone() for param in global_model.parameters()]\n",
    "\n",
    "                # initial list to collect local model weights after scaling\n",
    "                scaled_local_weight_list = list()\n",
    "\n",
    "                # randomize client data - using keys\n",
    "                client_names = list(clients_batched.keys())\n",
    "                random.shuffle(client_names)\n",
    "\n",
    "\n",
    "                for client in client_names:\n",
    "                    smlp_local = SimpleMLP(X.shape[1], 1)\n",
    "                    local_model = smlp_local\n",
    "                    # set local model weight to the weight of the global model\n",
    "                    local_model.load_state_dict({name: param.clone() for name, param in zip(local_model.state_dict(), global_weights)})\n",
    "                    optimizer = torch.optim.SGD(local_model.parameters(), lr=0.01)\n",
    "\n",
    "                    # fit local model with client's data\n",
    "                    train_loader = DataLoader(TensorDataset(torch.tensor(clients_batched[client].dataset.tensors[0], dtype=torch.float32),\n",
    "                                                            torch.tensor(clients_batched[client].dataset.tensors[1], dtype=torch.float32)),\n",
    "                                              batch_size=32, shuffle=True)\n",
    "\n",
    "                    eps = 0.01  # Perturbation size\n",
    "\n",
    "                    train_model(local_model, train_loader, loss, optimizer,eps)\n",
    "\n",
    "                        \n",
    "                    # scale the model weights and add to the list\n",
    "                    scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "                    scaled_weights = scale_model_weights(local_model.state_dict().values(), scaling_factor)\n",
    "                    scaled_local_weight_list.append(scaled_weights)\n",
    "\n",
    "                    # clear session to free memory after each communication round\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                \n",
    "                # to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "                average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "\n",
    "                # update global model\n",
    "                for param, avg_param in zip(global_model.parameters(), average_weights):\n",
    "                    param.data.copy_(avg_param)\n",
    "\n",
    "                # test global model and print out metrics after each communications round\n",
    "                for X_test_batch, Y_test_batch in test_batched:\n",
    "                    global_acc, global_loss, global_f1, global_precision, global_recall, global_auc, global_fpr = test_model(X_test_batch, Y_test_batch, global_model, comm_round)\n",
    "                    all_results.append([global_acc, global_loss, global_f1, global_precision, global_recall, global_auc, global_fpr])\n",
    "\n",
    "            all_R = pd.DataFrame(all_results, columns=['global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "            flname = f'results/round-{r}/{cl}-clients/FedAvg-{dataset[d]}-results.csv'\n",
    "            all_R.to_csv(flname, index=None)\n",
    "\n",
    "            all_avg.append(np.concatenate(([dataset[d], r, cl], np.mean(all_results, axis=0))))  # Storing avg values for each dataset\n",
    "            all_std.append(np.concatenate(([dataset[d], r, cl], np.std(all_results, axis=0))))  # Storing std values for each dataset\n",
    "\n",
    "ALL_AVG = pd.DataFrame(all_avg, columns=['Dataset', 'num of round', 'num of clients', 'global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_AVG.to_csv('FedAvg-results.csv')\n",
    "\n",
    "ALL_STD = pd.DataFrame(all_std, columns=['Dataset', 'num of round', 'num of clients', 'global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_STD.to_csv('FedAvg-all-std-results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((all_avg[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2893319",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_avg =[]\n",
    "\n",
    "all_std =[]\n",
    "\n",
    "n_clients = [5,10,15]\n",
    "n_round = [10,20]\n",
    "\n",
    "\n",
    "dataset = ['Drebin', 'Malgenome', 'Kronodroid', 'Tuandromd' ]\n",
    "\n",
    "\n",
    "for d in range(0,1):\n",
    "    if d == 0:\n",
    "        use_data = Drebin_data\n",
    "    elif d==1:\n",
    "        use_data = Malgenome_data\n",
    "    elif d==2:\n",
    "        use_data = Kronodroid_data\n",
    "    elif d==3:\n",
    "        use_data = Tuandromd_data\n",
    "        \n",
    "        \n",
    "    print('===================================================================================================')\n",
    "    print('Working with:',dataset[d])\n",
    "    print('===================================================================================================')\n",
    "\n",
    "    for r in n_round: #number of rounds loop\n",
    "        comms_round = r\n",
    "        for cl in n_clients: #number of clients loop\n",
    "            number_of_clients = cl\n",
    "\n",
    "            # from sklearn.utils import shuffle\n",
    "            # use_data = shuffle(use_data)\n",
    "            # use_data\n",
    "            print('---------------------------------------------')\n",
    "            print('No. of Clients:', number_of_clients)\n",
    "            print('No. of Rounds:', comms_round)\n",
    "            print('---------------------------------------------')\n",
    "\n",
    "\n",
    "            features = np.array(use_data.iloc[:,range(0,use_data.shape[1]-1)]) #feature set\n",
    "\n",
    "            labels = use_data.iloc[:,-1] #labels --> B : Benign and S\n",
    "\n",
    "\n",
    "            #Do feature scaling \n",
    "\n",
    "\n",
    "            X = preprocessing.StandardScaler().fit(features).transform(features)\n",
    "\n",
    "\n",
    "            #binarize the labels\n",
    "            lb = LabelBinarizer()\n",
    "            y = lb.fit_transform(labels)\n",
    "\n",
    "\n",
    "            #split data into training and test set\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                                y, shuffle=True,\n",
    "                                                                test_size=0.2, \n",
    "                                                                random_state=100)\n",
    "\n",
    "\n",
    "\n",
    "            #create clients -- Horizontal FL\n",
    "            clients = create_clients(X_train, y_train, num_clients=number_of_clients, initial='client')\n",
    "\n",
    "            #process and batch the training data for each client\n",
    "            clients_batched = dict()\n",
    "            for (client_name, data) in clients.items():\n",
    "                clients_batched[client_name] = batch_data(data)\n",
    "\n",
    "\n",
    "                #process and batch the test set  \n",
    "            test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))\n",
    "\n",
    "            #==============================================\n",
    "            # Traditional FedAvg 2017\n",
    "            #==============================================\n",
    "            #-----------------------------------------------\n",
    "\n",
    "\n",
    "            all_results=list()\n",
    "\n",
    "            #create optimizer\n",
    "            lr = 0.01 \n",
    "            loss='binary_crossentropy'\n",
    "            metrics = ['accuracy']\n",
    "            optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr, \n",
    "                            decay=lr / comms_round, \n",
    "                            momentum=0.9\n",
    "                           )\n",
    "\n",
    "            #initialize global model\n",
    "            smlp_global = SimpleMLP()\n",
    "            global_model = smlp_global.build(X.shape[1],1)\n",
    "            #-----------------------------------------------\n",
    "\n",
    "\n",
    "            print('|=======================|')\n",
    "            print('|Traditional FedAvg 2017|')\n",
    "            print('|=======================|')\n",
    "\n",
    "            #commence global training loop\n",
    "            for comm_round in range(comms_round):\n",
    "\n",
    "                # get the global model's weights - will serve as the initial weights for all local models\n",
    "                global_weights = global_model.get_weights()\n",
    "\n",
    "                #initial list to collect local model weights after scalling\n",
    "                scaled_local_weight_list = list()\n",
    "\n",
    "                #randomize client data - using keys\n",
    "                client_names= list(clients_batched.keys())\n",
    "                random.shuffle(client_names)\n",
    "\n",
    "                #loop through each client and create new local model\n",
    "                for client in client_names:\n",
    "                    smlp_local = SimpleMLP()\n",
    "                    local_model = smlp_local.build(X.shape[1],1)\n",
    "                    local_model.compile(loss=loss, \n",
    "                                  optimizer=optimizer, \n",
    "                                  metrics=metrics)\n",
    "\n",
    "                    #set local model weight to the weight of the global model\n",
    "                    local_model.set_weights(global_weights)\n",
    "\n",
    "                    #fit local model with client's data\n",
    "                    local_model.fit(clients_batched[client], epochs=32, verbose=0)\n",
    "\n",
    "                    #scale the model weights and add to list\n",
    "                    scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "                    scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "                    scaled_local_weight_list.append(scaled_weights)\n",
    "\n",
    "                    #clear session to free memory after each communication round\n",
    "                    keras.backend.clear_session()\n",
    "\n",
    "                #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "                average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "\n",
    "                #update global model \n",
    "                global_model.set_weights(average_weights)\n",
    "\n",
    "                #test global model and print out metrics after each communications round\n",
    "                for(X_test, Y_test) in test_batched:\n",
    "                    global_acc, global_loss, global_f1, global_precision, global_recall, global_auc, global_fpr = test_model(X_test, Y_test, global_model, comm_round)\n",
    "                    all_results.append([global_acc,global_loss.numpy(),global_f1, global_precision, global_recall, global_auc, global_fpr])\n",
    "\n",
    "\n",
    "\n",
    "            all_R = pd.DataFrame(all_results, columns=['global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "            flname = 'results/round-'+str(r)+'/'+str(cl)+'-clients/FedAvg-'+dataset[d]+'-results.csv'\n",
    "            all_R.to_csv(flname, index=None)\n",
    "            \n",
    "            \n",
    "            all_avg.append(np.concatenate(([dataset[d],r,cl],np.mean(all_results,axis=0)))) #Storing avg values for each dataset\n",
    "            all_std.append(np.concatenate(([dataset[d],r,cl],np.std(all_results,axis=0)))) #Storing std values sfor each dataset\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "ALL_AVG = pd.DataFrame(all_avg, columns = ['Dataset', 'num of round', 'num of cliends','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_AVG.to_csv(f'FedAvg-results.csv')     \n",
    "\n",
    "ALL_STD = pd.DataFrame(all_std, columns = ['Dataset', 'num of round', 'num of cliends','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_STD.to_csv('FedAvg-all-std-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6104c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_AVG = pd.DataFrame(all_avg, columns = ['Dataset','Rounds','no-clients','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_AVG.to_csv('FedAvg-all-avg-results.csv')\n",
    "\n",
    "ALL_STD = pd.DataFrame(all_std, columns = ['Dataset','Rounds','no-clients','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_STD.to_csv('FedAvg-all-std-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "# make a little extra space between the subplots\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "s1 = np.array(all_results) #FedAvg\n",
    "\n",
    "t = range(0,s1.shape[0])\n",
    "\n",
    "ax1.plot(t, s1[:,0],label='Acc of FedAvg')\n",
    "ax1.set_xlim(0,s1.shape[0])\n",
    "ax1.set_xlabel('Rounds')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_ylim(0.98,1)\n",
    "ax1.grid(True)\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2.plot(t, s1[:,1],label='Error of FedAvg')\n",
    "ax2.set_xlim(0, s1.shape[0])\n",
    "ax2.set_xlabel('Rounds')\n",
    "ax2.set_ylabel('error')\n",
    "ax2.grid(True)\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3861d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b54df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
